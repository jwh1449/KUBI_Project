{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3b415aac794bdf98bf7f4e17027195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Choose:', options=('A', 'B', 'C'), value='A')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "dropdown = widgets.Dropdown(options=['A', 'B', 'C'], description='Choose:')\n",
    "display(dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "jsZ1B5Uv06Bx",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "8cb58387-ae79-4f2b-c847-434862ca2da5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-039siu72\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-039siu72\n",
      "  Resolved https://github.com/huggingface/transformers to commit b7fc2daf8b3fe783173c270d592073aabfb426cb\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0.dev0) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0.dev0) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0.dev0) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0.dev0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0.dev0) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0.dev0) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.51.0.dev0) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.51.0.dev0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.0.dev0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.0.dev0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.0.dev0) (2025.1.31)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for transformers: filename=transformers-4.51.0.dev0-py3-none-any.whl size=11092339 sha256=450c5c3cb053ee48d2680f088184205681d6fd85cc03e1d878ecae9c73c12881\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-8t4he4va/wheels/04/a3/f1/b88775f8e1665827525b19ac7590250f1038d947067beba9fb\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.50.0\n",
      "    Uninstalling transformers-4.50.0:\n",
      "      Successfully uninstalled transformers-4.50.0\n",
      "Successfully installed transformers-4.51.0.dev0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "fc15a4e0c50d450483d04bc6916827db",
       "pip_warning": {
        "packages": [
         "transformers"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jiwer\n",
      "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
      "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
      "  Downloading rapidfuzz-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
      "Downloading rapidfuzz-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
      "Successfully installed jiwer-3.1.0 rapidfuzz-3.12.2\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.29.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.12.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "32f4f35f41534983819a48f443b9b9ca",
       "pip_warning": {
        "packages": [
         "nvidia"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.11/dist-packages (4.51.0.dev0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.6.0+cu124)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (1.5.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->transformers[torch]) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets>=2.6.1\n",
    "!pip install git+https://github.com/huggingface/transformers\n",
    "!pip install evaluate>=0.30\n",
    "!pip install jiwer\n",
    "!pip install accelerate -U\n",
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "onR_YSX8adn6"
   },
   "outputs": [],
   "source": [
    "json_data['RecordingMetadata']['prompt']\n",
    "json_data['SpeakerMetadata']['topik_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "58-B7qAq7Ati"
   },
   "outputs": [],
   "source": [
    "# 1. 오디오 파일 경로 취합\n",
    "import glob\n",
    "\n",
    "path = \"/content/drive/MyDrive/STTDATA/데이터모음/원본데이터/*\"\n",
    "raw_data_list = glob.glob(path)\n",
    "raw_data_list = sorted(raw_data_list)\n",
    "print(f\"file_list : {raw_data_list[:10]}\")\n",
    "print(len(raw_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGWg1HJL7PXj"
   },
   "outputs": [],
   "source": [
    "# 2. json 파일 경로 취합\n",
    "import glob\n",
    "\n",
    "path = \"/content/drive/MyDrive/STTDATA/데이터모음/정답데이터/*\"\n",
    "labeled_data_list = glob.glob(path)\n",
    "labeled_data_list = sorted(labeled_data_list)\n",
    "print(f\"file_list : {labeled_data_list[:10]}\")\n",
    "print(len(labeled_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llyYgM638Noy"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "transcript_list = []\n",
    "for labeled_data in tqdm(labeled_data_list):\n",
    "    with open(labeled_data, \"r\", encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "        json_data = json_data['RecordingMetadata']['orthographic']\n",
    "        transcript_list.append(json_data)\n",
    "\n",
    "df = pd.DataFrame(data=transcript_list, columns = [\"transcript\"])\n",
    "\n",
    "# 텍스트 데이터로 만든 데이터프레임에 음성 파일 경로 컬럼을 추가\n",
    "df[\"raw_data\"] = raw_data_list\n",
    "\n",
    "# Null data 유무 확인\n",
    "df.isnull().values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uWpbKSDMPqII"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "0xcp1OgWMr4e",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from datasets import Audio\n",
    "\n",
    "# 오디오 파일 경로를 dict의 \"audio\" 키의 value로 넣고 이를 데이터셋으로 변환\n",
    "# 이때, Whisper가 요구하는 사양대로 Sampling rate는 16,000으로 설정한다.\n",
    "ds = Dataset.from_dict({\"audio\": [path for path in df[\"raw_data\"]],\n",
    "                       \"transcripts\": [transcript for transcript in df[\"transcript\"]]}).cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "\n",
    "# 데이터셋을 훈련 데이터와 테스트 데이터, 밸리데이션 데이터로 분할\n",
    "train_testvalid = ds.train_test_split(test_size=0.2)\n",
    "test_valid = train_testvalid[\"test\"].train_test_split(test_size=0.5)\n",
    "datasets = DatasetDict({\n",
    "    \"train\": train_testvalid[\"train\"],\n",
    "    \"test\": test_valid[\"test\"],\n",
    "    \"valid\": test_valid[\"train\"]})\n",
    "\n",
    "# 작성한 데이터셋을 허깅페이스에 업로드\n",
    "datasets.push_to_hub(\"jwh1449/AIhub_foreign_dataset\")\n",
    "print(\"완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "W2Z92SEtyTMw"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00ee28f52754a7b9acc11b33de87e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OpaRsvbRXI0P"
   },
   "outputs": [],
   "source": [
    "# 1. 오디오 파일 경로 취합\n",
    "import glob\n",
    "\n",
    "path = \"/content/drive/MyDrive/STTDATA/데이터모음/원본데이터/*\"\n",
    "raw_data_list = glob.glob(path)\n",
    "raw_data_list = sorted(raw_data_list)\n",
    "print(f\"file_list : {raw_data_list[:10]}\")\n",
    "print(len(raw_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uVrSIEIeb8zV"
   },
   "outputs": [],
   "source": [
    "# 2. json 파일 경로 취합\n",
    "import glob\n",
    "\n",
    "path = \"/content/drive/MyDrive/STTDATA/데이터모음/정답데이터/*\"\n",
    "labeled_data_list = glob.glob(path)\n",
    "labeled_data_list = sorted(labeled_data_list)\n",
    "print(f\"file_list : {labeled_data_list[:10]}\")\n",
    "print(len(labeled_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4d62O5gW9Di"
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperFeatureExtractor, WhisperTokenizer\n",
    "\n",
    "# 파인튜닝을 진행하고자 하는 모델의 feature extractor를 로드\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-base\")\n",
    "\n",
    "# 파인튜닝을 진행하고자 하는 모델의 tokenizer를 로드\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-base\", language=\"Korean\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2qQFXG9fjNX"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 전체 데이터셋에서 각 split의 50%만 불러오기\n",
    "low_call_voices = load_dataset(\n",
    "    \"jwh1449/AIhub_foreign_dataset\",\n",
    "    split={\n",
    "        \"train\": \"train[:50%]\",\n",
    "        \"test\": \"test[:50%]\",\n",
    "        \"valid\": \"valid[:50%]\"\n",
    "    }\n",
    ")\n",
    "\n",
    "low_call_voices.push_to_hub(\"jwh1449/AIhub_foreign_dataset2\")\n",
    "print(\"완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fg3ysvRtg2fI"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 전체 데이터셋에서 각 split의 50%만 불러오기\n",
    "low_call_voices = load_dataset(\n",
    "    \"jwh1449/AIhub_foreign_dataset\",\n",
    "    split={\n",
    "        \"train\": \"train[-50%:]\",\n",
    "        \"test\": \"test[-50%:]\",\n",
    "        \"valid\": \"valid[-50%:]\"\n",
    "    }\n",
    ")\n",
    "\n",
    "low_call_voices.push_to_hub(\"jwh1449/AIhub_foreign_dataset3\")\n",
    "print(\"완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "NPxQgOeegwxi",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 데이터셋을 업로드할 때 접근을 제한하거나 비공개로 설정한 경우 허깅페이스 로그인이 필요하다.\n",
    "low_call_voices = load_dataset(\"jwh1449/AIhub_foreign_dataset3\")\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    # 오디오 파일을 16kHz로 로드\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # input audio array로부터 log-Mel spectrogram 변환\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # target text를 label ids로 변환\n",
    "    batch[\"labels\"] = tokenizer(batch[\"transcripts\"]).input_ids\n",
    "    return batch\n",
    "\n",
    "# # 널값(결측치) 제거 함수 정의\n",
    "# def remove_null(example):\n",
    "#     return example[\"audio\"] is not None and example[\"transcripts\"] is not None\n",
    "\n",
    "# # 널값 제거\n",
    "# low_call_voices = low_call_voices.filter(remove_null)\n",
    "\n",
    "low_call_voices = low_call_voices.map(prepare_dataset, remove_columns=low_call_voices.column_names[\"train\"], num_proc=None)\n",
    "\n",
    "# 전처리 작업이 오래 걸릴 수 있으므로, colab을 사용하여 파인튜닝을 진행한다면 전처리가 완료된 데이터셋을 Hub에 저장하는 것을 추천한다.\n",
    "low_call_voices.push_to_hub(\"jwh1449/AIhub_foreign_dataset5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "4435c707f439427faa83830fba3373e2",
      "ac9245f2e7b848daa7439117442a961e",
      "c25e8e76861b4c679e584a624f0acf88",
      "6ea53ce7dcb04f8cbcd0ac0f7fabb9ca",
      "f8ecfb9c24d74e868294e542e92be9c5",
      "696f1cb70b6c4783ac50a9c435c9a30a",
      "85a37178556a449d9f00595cb7802522",
      "d4f265765d5d474587548afc701f882f",
      "1967d719c1904de6b8e3b8ad98b60b49",
      "4001d1b6b0ee42be8e795f256ac08e9a",
      "d73ac9c891ed48f2ae782dc664bf440b",
      "9b4a05a5cd23493e81ff0646bf7b3135",
      "604e389834c14d09b4673a7b488f9bcd",
      "9399f88d50dc43fab8a3b5ec8059411c",
      "67bbf9006836470dbf2cbd197cc76768",
      "f702471f8b364143aa2aac7897b3ca67",
      "0b470120c9d4468494886cfb594171e1",
      "c164dc91ecb748dfa0910681105ff263",
      "50eb4d5b04974c55a5c45ca679579079",
      "84fc55af490d407fb430b18a136ace5c"
     ]
    },
    "id": "KxfCGiAeNg-9",
    "outputId": "4aa276be-7dab-4d6d-e449-66a27fe276a1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71eb45bbca2241f6b9790e50c959427a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d12044e61bd0474e8653b1872a445956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/197 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9760dcb119154ac4853d7663ccb36628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오류: Unable to find '/home/aiuser/kospeech_parquet/valid-00000.parquet'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import hashlib\n",
    "import os\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# # dataset_info.json의 download_checksums (실제로는 전체 목록 필요)\n",
    "# # 아래는 예시로, 실제 dataset_info.json 파일에서 모든 URL과 체크섬을 가져와야 함\n",
    "# dataset_info = {\n",
    "#     \"download_checksums\": {\"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00000-of-00195.parquet\": {\"num_bytes\": 100252687, \"checksum\": \"1f32d12bb6db19b0cfdca6487858cce73c0653e551792dabbdaa8d91fa347b63\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00001-of-00195.parquet\": {\"num_bytes\": 102863477, \"checksum\": \"0c358a982ca204420635f39c14703a7d8de60c30a4da278485b8b324c0ae7e50\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00002-of-00195.parquet\": {\"num_bytes\": 97553573, \"checksum\": \"7422b478682fed3d911db92e53f5f5e97ba7de22e309e0df869c7e8c1d89b884\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00003-of-00195.parquet\": {\"num_bytes\": 102058998, \"checksum\": \"796d324dca3219b894431185a247a9b6e9ad6271ff33babd7b47526c5c2301e0\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00004-of-00195.parquet\": {\"num_bytes\": 102557342, \"checksum\": \"fcd2368818cc6b0aeb4f17483b41c855d45ee707f404cc3c5e3603b338f2a242\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00005-of-00195.parquet\": {\"num_bytes\": 94543367, \"checksum\": \"a68dd19bf94a0b760f6df058aced07849e34fb295106b6c401167d6a627f03bf\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00006-of-00195.parquet\": {\"num_bytes\": 97549740, \"checksum\": \"77c7d93c553049b7a0b94f2a1d4ec8c34e6d79fe9bb6f00e263c96e56e4ea92c\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00007-of-00195.parquet\": {\"num_bytes\": 100679315, \"checksum\": \"163e860d488cc8d4c6439ddb020bb8cc302b582690ecc4b455a4b376e99b385e\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00008-of-00195.parquet\": {\"num_bytes\": 101449800, \"checksum\": \"0bcdd9a596f7db111f44a98430b728975cd03a248b3ec4fec58963932fa7bba6\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00009-of-00195.parquet\": {\"num_bytes\": 98479253, \"checksum\": \"a6efacb41b5a5d28bc07ce4836d5066be691e0ef044e6081ecf210f778de9e01\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00010-of-00195.parquet\": {\"num_bytes\": 98530080, \"checksum\": \"97b5c591ddcb19ff703cd03c1aaa4eb17e1fa4ff1840897899377eaf3000fa8e\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00011-of-00195.parquet\": {\"num_bytes\": 103423772, \"checksum\": \"28ec08c1cb66cce83bd7171d274c2e3d0cd92230b9a86544d638c88094513279\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00012-of-00195.parquet\": {\"num_bytes\": 100100765, \"checksum\": \"e4a1bcf0b298c43b889f63e9fdbbf3b00af16e4e681c8626ed9ced19306eae46\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00013-of-00195.parquet\": {\"num_bytes\": 97773711, \"checksum\": \"b2d2a2c5b84f61f6838012fce5d2276497caa46ef110b3210c5c629df3f3384a\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00014-of-00195.parquet\": {\"num_bytes\": 96435404, \"checksum\": \"2d4257fdc13b21ab13074c68df677b3727be084677756aa5400511c85dd1f3a8\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00015-of-00195.parquet\": {\"num_bytes\": 93360724, \"checksum\": \"6e38451d11a428a4f35a59615d9dba4e93fcc2c16dc64b5bfc680f6113fb892f\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00016-of-00195.parquet\": {\"num_bytes\": 102500345, \"checksum\": \"6c43f756bebe5df5f2ca781552d1e85f3fcf64ef28ebb9315c049688a4babe9c\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00017-of-00195.parquet\": {\"num_bytes\": 98567065, \"checksum\": \"a374295dfb1f2e5030b6a008375cca4c3d1e772f6ab1e7330e87f7c492c8b92a\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00018-of-00195.parquet\": {\"num_bytes\": 102443838, \"checksum\": \"df57a8ec9f41c8835349e0e0765baf72b9bea3c8e2103b53a090a0fa183ba66a\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00019-of-00195.parquet\": {\"num_bytes\": 99915229, \"checksum\": \"c6e8b3c6e5b3637f69ad3616dd51fff20783dcc3fccd7b67ec3dfa7bdcce708e\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00020-of-00195.parquet\": {\"num_bytes\": 98568022, \"checksum\": \"e2c7758cd42bc6809856c39dc2ca9b69a28a6ec59eeccf0137d7090168bdc459\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00021-of-00195.parquet\": {\"num_bytes\": 97740081, \"checksum\": \"e1102f3242789683631f6643d83131b0c58733fbcadea7967817c871fb573ded\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00022-of-00195.parquet\": {\"num_bytes\": 98912387, \"checksum\": \"17ac8d8afbca377df97d8d2435b28f83a51f413d667ad3ad23a590f537c0bfb8\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00023-of-00195.parquet\": {\"num_bytes\": 106989107, \"checksum\": \"830ce6af6ccb668ab43764f4ea18e109328501ad28789064b4240d40b60819d5\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00024-of-00195.parquet\": {\"num_bytes\": 99768537, \"checksum\": \"50c13920d751d35b6ad9d578a9d92beed7f5d25a94b5904dd57ab69181f18d31\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00025-of-00195.parquet\": {\"num_bytes\": 98668265, \"checksum\": \"19b2b64abbff4442322359d45085602ebd92a974f1abbe32c469f3a9eab17c3e\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00026-of-00195.parquet\": {\"num_bytes\": 101951922, \"checksum\": \"bd32bb81793e5c41d9d5be7324e5eaa3f573edd9f1a4aa610b2f501d7699f267\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00027-of-00195.parquet\": {\"num_bytes\": 104000646, \"checksum\": \"990a7f359846a95f37a4017dea70bacd585cf663e28a6648d31275014d3e735a\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00028-of-00195.parquet\": {\"num_bytes\": 98862855, \"checksum\": \"2a5453a82c703aaf150c3ba943185722c2776ef420dcd4f8b4c28a1fc4fa70a8\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00029-of-00195.parquet\": {\"num_bytes\": 99843928, \"checksum\": \"59592b7d34003be2fd97e1177b24eb9ccda2381c964d31bbdb3cdf7391bb0395\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00030-of-00195.parquet\": {\"num_bytes\": 103428341, \"checksum\": \"4249829b8f6b78d58d058b12fd9153931161c9055851fa8fedcc25c75908b628\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00031-of-00195.parquet\": {\"num_bytes\": 98065680, \"checksum\": \"c06f471172543e6a80988df01664596c47a50c8c90152eb331107262d4635d8a\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00032-of-00195.parquet\": {\"num_bytes\": 101062510, \"checksum\": \"93e1dc952669620ffb40602d705202189a4961000c7237ab4cf8c708fa45b983\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00033-of-00195.parquet\": {\"num_bytes\": 102833091, \"checksum\": \"f0351163b22218158fc99fb493be7d50711dc6e625e523f084be70bc88e79a71\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00034-of-00195.parquet\": {\"num_bytes\": 104779790, \"checksum\": \"836fd3e6b8afb104cf6fb99ed036c8a9086a5a07a1aaec316e0637c2026b1ca7\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00035-of-00195.parquet\": {\"num_bytes\": 99821835, \"checksum\": \"6f22c3e74bb95a402f4fe15ac15a476811bfe84f67f32a766490fbe4a3112c0a\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00036-of-00195.parquet\": {\"num_bytes\": 93542275, \"checksum\": \"b65270209a6d5468c9208b53a3a65d1d53eb72782aff62d9e272d352d7123efa\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00037-of-00195.parquet\": {\"num_bytes\": 99260833, \"checksum\": \"1e5af547d99987f1b4a62b5ad7a0dfb48cd7813036aa1e40e43bd6c35b21ef7c\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00038-of-00195.parquet\": {\"num_bytes\": 101903896, \"checksum\": \"649be42de88ee9ca99793fa28c4bde271092d0fe2263eac847c5fb5a95bd1fb6\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00039-of-00195.parquet\": {\"num_bytes\": 96184770, \"checksum\": \"7c23f7afbea59bd90e2541975f284141fb7824fc9624e3ecca73a10037555008\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00040-of-00195.parquet\": {\"num_bytes\": 99638693, \"checksum\": \"894928b865d2a27f7ce8fb267a32140b4ee17dede09b7ef0275d1aa33f8374b8\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00041-of-00195.parquet\": {\"num_bytes\": 103277487, \"checksum\": \"86af36a8e41fc241d3d0110ceb0fe3b594e900fda8a0ae6f14d3518d5800ba00\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00042-of-00195.parquet\": {\"num_bytes\": 101901393, \"checksum\": \"6a0990bf99417085a7b471a06e1908b3ba1376c18b8c20da7442e82a78e80723\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00043-of-00195.parquet\": {\"num_bytes\": 98995965, \"checksum\": \"d4d29bc932650254f45b397163ecaf164adf0eb23224f4637a21b9897eeb13ec\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00044-of-00195.parquet\": {\"num_bytes\": 98867988, \"checksum\": \"a5297faf3f40de64c846ed550a0a4880a5394ed9d788a8ae447a684e88078dce\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00045-of-00195.parquet\": {\"num_bytes\": 101367819, \"checksum\": \"812f0f068fdf263ef81b0b7c945843eff13240ebec7044269245ceab56d6ec22\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00046-of-00195.parquet\": {\"num_bytes\": 103235035, \"checksum\": \"1731976ae6122151f863100c6634918882aadf0295122678407d66ef9906b5f0\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00047-of-00195.parquet\": {\"num_bytes\": 102667277, \"checksum\": \"1a5b40477c5a6898d5aebe6c05c377d79d22430ef6c6bc6986f45f3ba06f84ef\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00048-of-00195.parquet\": {\"num_bytes\": 97114352, \"checksum\": \"5e7e38d0ced261f97f0d7d89391ec87c95b2d96f86bba4d9baa282e2a8ab1c7a\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00049-of-00195.parquet\": {\"num_bytes\": 100689272, \"checksum\": \"da4fbfc91841fa4bd847856848f0ecfe8a8d5a7e21c3d1895166d9bd4d58e869\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00050-of-00195.parquet\": {\"num_bytes\": 100248465, \"checksum\": \"9847aaa601cef938e5e02b876d76f3754a7411a2a90154b07464d03f6c77bef9\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00051-of-00195.parquet\": {\"num_bytes\": 103017674, \"checksum\": \"542d733e3cfb5090818147d1b19f6bd18bd7a0bbec861a54c5905a108e19edde\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00052-of-00195.parquet\": {\"num_bytes\": 103144949, \"checksum\": \"cac8e3a0eebeada0f2228d1519ae8d89e5360e8bfd4d6b41abf1953102cdd698\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00053-of-00195.parquet\": {\"num_bytes\": 99702224, \"checksum\": \"f8c2d63faac987cffddc1ea8f42a7852e130b8616d0568f33c8121825619d62c\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00054-of-00195.parquet\": {\"num_bytes\": 97196525, \"checksum\": \"5e40c5f3df24a4cf01531a9d9fd4af19181d66433cf646d03293316284756f75\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00055-of-00195.parquet\": {\"num_bytes\": 105572479, \"checksum\": \"7841914ab7dbaa5a6e283fbf3bcdfe64e0a8a65048964a2f057db1cb1272074e\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00056-of-00195.parquet\": {\"num_bytes\": 100644911, \"checksum\": \"18ebedad80158a140b479042967711f184ab3ac1bc9687c913adf64f8e5ec6d2\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00057-of-00195.parquet\": {\"num_bytes\": 97622217, \"checksum\": \"49aaae5d5b073f39e3f9f053e7df2b58067b603363334d4907c342f8b63aeb13\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00058-of-00195.parquet\": {\"num_bytes\": 98067309, \"checksum\": \"0bcc13cc1d7c9522e1ece3881183136930a9a2a885026e9c5de102e393d50950\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00059-of-00195.parquet\": {\"num_bytes\": 99835430, \"checksum\": \"f01d491f86d17f5bab76eb1404125c7e4e7fbdcbc68304cd6946741888377329\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00060-of-00195.parquet\": {\"num_bytes\": 102597239, \"checksum\": \"04b0cdd02a4011931639f70a830174c549fb308f64afbbe164a42a51b7a3162f\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00061-of-00195.parquet\": {\"num_bytes\": 97821295, \"checksum\": \"30fe00a6b77ed16fb405602603ac8d3463a2ce5d44818a51a756e74012d3cb04\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00062-of-00195.parquet\": {\"num_bytes\": 97969074, \"checksum\": \"5a7c98355c9d2221fedbc208966661fcb52ea89f64ca761a8b201e8ceef02efc\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00063-of-00195.parquet\": {\"num_bytes\": 98750980, \"checksum\": \"23db78d2c19b4ac066a4b229599a30e602f5d91f7ca8c9bf38a91acf1d4cbc38\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00064-of-00195.parquet\": {\"num_bytes\": 100061595, \"checksum\": \"ce73da000d792def82b552c04619ae4cb8d2ec5e365b683e20b0656e70072ebc\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00065-of-00195.parquet\": {\"num_bytes\": 98190161, \"checksum\": \"a44c017cbdc5af0730fd9ca1559426063cad511e3270cd65c57c3e9b6f8fdfdf\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00066-of-00195.parquet\": {\"num_bytes\": 98522006, \"checksum\": \"436397e389b6273f9fd24f8966ce918b5c96bc8cd77e577780d0f7e8296099bc\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00067-of-00195.parquet\": {\"num_bytes\": 102761612, \"checksum\": \"2f597c2cc8c101b7659c6a49bad4fc5efbf29f8588c4cfc43b0f572ebbea7b11\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00068-of-00195.parquet\": {\"num_bytes\": 100386420, \"checksum\": \"9959133152b21a31b6d15051e3ac5600ff278c3fdcbf90dadbe1a53d348d07c4\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00069-of-00195.parquet\": {\"num_bytes\": 100968069, \"checksum\": \"d2d816884c306b5b29c7252f97c6958c51caeed267c33ffa1ef5c3d2989a81e2\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00070-of-00195.parquet\": {\"num_bytes\": 99963790, \"checksum\": \"a49bec4730dafc104c60107fd155d72c3c4d8e7a71bcca2893feee28bbffac80\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00071-of-00195.parquet\": {\"num_bytes\": 97248974, \"checksum\": \"a13cff42cb0617ebf6f2497265d602df24e5fd1d41b8e0f5eff83bbe45fc4731\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00072-of-00195.parquet\": {\"num_bytes\": 104225622, \"checksum\": \"3223b0515421003beaa3fef98504e40cfb00350f94c3725783a15a923b8e15c3\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00073-of-00195.parquet\": {\"num_bytes\": 100460519, \"checksum\": \"f74626d9dad6156ce95a5e671e226781e1d51bcd3a518631d37d52a9792f2b76\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00074-of-00195.parquet\": {\"num_bytes\": 100764484, \"checksum\": \"6d930ea8f4a71b6f3b548764e932b26e5f82056f23a4c3aac8e1a6aba2c7b447\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00075-of-00195.parquet\": {\"num_bytes\": 109015417, \"checksum\": \"b8d644480440592c9c680adbd7c8ffe5651fa8ecafabea5776c1b5ea4a8a7892\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00076-of-00195.parquet\": {\"num_bytes\": 100757779, \"checksum\": \"729edb903b77123bde14d3132dbbedb8f528c08146cae9757a4386c5fa2f3de0\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00077-of-00195.parquet\": {\"num_bytes\": 97654748, \"checksum\": \"3a72c5b07c1ee587e292985a9d47d61fbb6d352ef1d142fdb994238ff11bf4e2\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00078-of-00195.parquet\": {\"num_bytes\": 100422146, \"checksum\": \"79642171f09e1dc4bb814bb42814616518e35fde9e639a4b941cb5a842d73abc\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00079-of-00195.parquet\": {\"num_bytes\": 99676697, \"checksum\": \"0ff67e540713fb6d743064ec3780f99935fccf1c0fef2d40533f21aa79682d32\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00080-of-00195.parquet\": {\"num_bytes\": 99748169, \"checksum\": \"8fc6244da5f7fdf2229ab2053669b329bfa4bb11c02b7d06fe45380e44fd568b\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00081-of-00195.parquet\": {\"num_bytes\": 96963878, \"checksum\": \"5effa91f140468ae9812ca5da21c2327d5af32861b7f39ae2eb4ceab89c1d0db\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00082-of-00195.parquet\": {\"num_bytes\": 106574443, \"checksum\": \"a928cd202c1054965252d41bb05dd0839bc5ac7deace43ef917c805cb2ba5076\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00083-of-00195.parquet\": {\"num_bytes\": 101682892, \"checksum\": \"0e13b62f6eeb8aca263b6b5785f6932cf435339f6dac07ebbb87611df786de09\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00084-of-00195.parquet\": {\"num_bytes\": 100266629, \"checksum\": \"c44d69efb2931ac4dead58e3765971eb4c237a0fcc5f30608d42cfea220479c9\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00085-of-00195.parquet\": {\"num_bytes\": 102561645, \"checksum\": \"bc8aac0868179f80a03662e8b780f25d941933753d1ff43d474d335a9dce79fd\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00086-of-00195.parquet\": {\"num_bytes\": 102408655, \"checksum\": \"6dc141d0667aacfdbd1a05d4e771a7b7590b322a75db77ff23d8de6f904f99cc\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00087-of-00195.parquet\": {\"num_bytes\": 100154367, \"checksum\": \"2a42714a2215e968deef5fc3292da1e9ff95af061ddde64f9b278bd98d75fd99\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00088-of-00195.parquet\": {\"num_bytes\": 97374168, \"checksum\": \"7a597fc516fd7c7b3d3332d02cf0222f57c6968204ed4d5fe35666e7f5f44c87\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00089-of-00195.parquet\": {\"num_bytes\": 98400762, \"checksum\": \"2cb25e42789b2b2b215503132a01900ef39370cd62552f2be023179db49e0f08\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00090-of-00195.parquet\": {\"num_bytes\": 96908400, \"checksum\": \"414d30bea7d79bdfb2296869d195dfe1fc86ff3aa0ad9795f9156261f6e08b2a\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00091-of-00195.parquet\": {\"num_bytes\": 104726738, \"checksum\": \"9ca8192f71936465126338e678d48f6a8b51fd8b75d63b3f39cd207775542d47\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00092-of-00195.parquet\": {\"num_bytes\": 98737345, \"checksum\": \"590192cc626f2948996cf01b21334859c401c2908aaae417b8fb116b410d391e\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00093-of-00195.parquet\": {\"num_bytes\": 97811903, \"checksum\": \"af783e568a0cf3718153c0ef84a3dde48ef8c151e5082548fdfdfdaa02907a15\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00094-of-00195.parquet\": {\"num_bytes\": 97845579, \"checksum\": \"10b24292604d9593f9923cfa0f66b2465098ac63d0cdb1e2242ebe03775080ff\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00095-of-00195.parquet\": {\"num_bytes\": 102364531, \"checksum\": \"e83de7d41cd962b508ffe6f806c50f70d9d69205b5f350e430bce28370538562\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00096-of-00195.parquet\": {\"num_bytes\": 103473423, \"checksum\": \"2d68e0cf446c2d3a0254d19e4a8452aa5fe19f2db2659a92445a472defc80265\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00097-of-00195.parquet\": {\"num_bytes\": 98971504, \"checksum\": \"9898f4ea61fe7416c1588b03e4869f7a9f82cd27a2f8718c63cb4a6eed666e26\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00098-of-00195.parquet\": {\"num_bytes\": 98320725, \"checksum\": \"0d967ea4be64d58b719a7ad65b7dea33ff6d68a6fc7682af60ff229bbbe896bb\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00099-of-00195.parquet\": {\"num_bytes\": 103256529, \"checksum\": \"ec07aad86aeb18e6089791e068b1cce42164499ccbf0d682a54a8dad255a812a\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00100-of-00195.parquet\": {\"num_bytes\": 96813983, \"checksum\": \"7bda4f6b4fa5ecd240bd1ee53e8adb45dd198be689bf9625efbfdda2b6b09baf\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00101-of-00195.parquet\": {\"num_bytes\": 100314977, \"checksum\": \"7539a22079e47a37bd1f91d86d3726a7ba037d243c7c5da59a775144a743c01f\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00102-of-00195.parquet\": {\"num_bytes\": 97107708, \"checksum\": \"4dbe56b67994f119f1c2a1699555bdbf25209a8f07c7a640d93c42f68799a7f8\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00103-of-00195.parquet\": {\"num_bytes\": 99113340, \"checksum\": \"78a5f95f48180c4fc7074ba402c45eac4f27464042fa24bdd93e32b5d022f498\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00104-of-00195.parquet\": {\"num_bytes\": 99668019, \"checksum\": \"f4ec4a8bdbc089f4edc2ab03c67cbfb767c6982365851bd681766b3bb6e55a27\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00105-of-00195.parquet\": {\"num_bytes\": 97189527, \"checksum\": \"9f5c93ec6f95ee12c12df7fd314a1e1a3bd8b728d76212ecd9d273735aaea8e2\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00106-of-00195.parquet\": {\"num_bytes\": 97554683, \"checksum\": \"f19aff5e79528476c46062a24a79f913a1ee2f2e1f0ada4267e56066608f8fec\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00107-of-00195.parquet\": {\"num_bytes\": 98059417, \"checksum\": \"209473b229565073e36fa6bdd8aee5e2485bf17639f3af5a8e4cc65ddc02abf6\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00108-of-00195.parquet\": {\"num_bytes\": 102041442, \"checksum\": \"b9ffcd76dea99445e0c859ad9fc7341c07282be01b294e31bcaf305ec6428af7\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00109-of-00195.parquet\": {\"num_bytes\": 99839921, \"checksum\": \"6a50b733840a2706f6a109c89a58c4e66e180829586ac404150a7c1078245c35\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00110-of-00195.parquet\": {\"num_bytes\": 98026862, \"checksum\": \"9ba4dec5f69cf6fdea68d35c7121beb1fa834f8d8869370f1d7ce150ff79a5df\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00111-of-00195.parquet\": {\"num_bytes\": 96283137, \"checksum\": \"0b3934702b8fbe2113a51e8d81e80c7824c2e5a4cc9b9b57c47f37e0fcc3db90\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00112-of-00195.parquet\": {\"num_bytes\": 100060752, \"checksum\": \"0b4c4fee8e34c1ba7d7f9e55768a6084fc5e693f1409742955252f0b3b615ce1\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00113-of-00195.parquet\": {\"num_bytes\": 100249833, \"checksum\": \"1f74e547df35147a1eb56733842da268c3ddb06f03c2ce8695a9ce7a3b419c3e\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00114-of-00195.parquet\": {\"num_bytes\": 103404463, \"checksum\": \"71f4c28c8893a58468b03d33ab9e868b7ee2a633d68948e6fc3afa44d124116b\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00115-of-00195.parquet\": {\"num_bytes\": 96118824, \"checksum\": \"e562848926b94458706cc17c1cc9963b5a1013cb893eb620177a662baaef5bb7\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00116-of-00195.parquet\": {\"num_bytes\": 98420426, \"checksum\": \"c5a8dc61245b756e4c5f2f5c858457ffa5243dc5ad5a24d9770d40ad8d73edaa\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00117-of-00195.parquet\": {\"num_bytes\": 93317565, \"checksum\": \"c50c5b081fa8b4937a26d4e3039f7f90ddeec6b34a71b0c0d4e5a8ee108aa03f\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00118-of-00195.parquet\": {\"num_bytes\": 99034327, \"checksum\": \"b0466034b166f5695bc14c5432ca96d6dc5f2cae0cf38d169f342f71e7130106\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00119-of-00195.parquet\": {\"num_bytes\": 99335308, \"checksum\": \"5042f5527918a3cdf9daa7f51ed3fd8e8d87bb15f35fec8aac44b85921ce28b5\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00120-of-00195.parquet\": {\"num_bytes\": 102895161, \"checksum\": \"6dc31c190092a6f17f947052f820c14bb6744c4da66c2f309df98aede99285a1\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00121-of-00195.parquet\": {\"num_bytes\": 100281363, \"checksum\": \"28f362afb85055d31e9cb905133e757aae26b1de4827baa4ffa307830921265e\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00122-of-00195.parquet\": {\"num_bytes\": 103444364, \"checksum\": \"439973752159f38802925ccaa1b6324567b6d2a2059a070eaa2c1a2b5c0318e8\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00123-of-00195.parquet\": {\"num_bytes\": 97909776, \"checksum\": \"9a15a3808c76fc4ac98ff41d957bf73e75710d5ecf7a739bc0927c7247effe8f\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00124-of-00195.parquet\": {\"num_bytes\": 103881788, \"checksum\": \"0a916ee8541a8c22684e28c34477f1b79c13382ec33951b05fbe74996d3748ce\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00125-of-00195.parquet\": {\"num_bytes\": 95400301, \"checksum\": \"cad71da4513fe211478d97c92307f8b1e2f7363c007479d7a19cd338410aa63d\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00126-of-00195.parquet\": {\"num_bytes\": 95561495, \"checksum\": \"644aae5decafb6257d6223cdb7fd4bdd6a12a36eec5e60c73d7799478a33cc39\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00127-of-00195.parquet\": {\"num_bytes\": 102054278, \"checksum\": \"ced45acc5b845d6096b3b75ebc9ed2dd2ea904a228e295ff4378047c59fa7c12\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00128-of-00195.parquet\": {\"num_bytes\": 97715527, \"checksum\": \"29be96fd1fa4619eca3490af6c57f39a1e833773892558a0692deecd090124ee\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00129-of-00195.parquet\": {\"num_bytes\": 101700671, \"checksum\": \"1b43cde828600a913870e7a72a1316fde6034392512870034f3850b4dc26fbf8\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00130-of-00195.parquet\": {\"num_bytes\": 105266734, \"checksum\": \"3c1c2b656bdf65fd35808e1a963a257859d3fc388c0aafd7d5d7838723971feb\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00131-of-00195.parquet\": {\"num_bytes\": 101136954, \"checksum\": \"be8e7f1b3912fe9a99c7b2457a0168a12d3d558acf410516ba23758ebac503a9\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00132-of-00195.parquet\": {\"num_bytes\": 95469215, \"checksum\": \"5cbab3790faff63b638362ce9431e92d5e56ee561ff5c9bb040bd9d9147fd8ce\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00133-of-00195.parquet\": {\"num_bytes\": 96956219, \"checksum\": \"dcba9f57d438b261f3dd5a68020a0b5abd7b398d477712f2fab92b800d8f34ae\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00134-of-00195.parquet\": {\"num_bytes\": 103740617, \"checksum\": \"764db74defe2203731ddd34dc5e0d8356856fa9e0a1c80e3d9ce3808a26be0c1\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00135-of-00195.parquet\": {\"num_bytes\": 103399775, \"checksum\": \"ff1aa9f0e00597fe90caf9fb92aa33c2fa5d0c2d331caa773a3bdd67781cb265\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00136-of-00195.parquet\": {\"num_bytes\": 98808378, \"checksum\": \"f03c16abb0f856d1e7f577e08fd31a1be141b39ca7ba238ed26a207647019f80\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00137-of-00195.parquet\": {\"num_bytes\": 97965072, \"checksum\": \"adb942a50f1ee3af5c8ec7aaacd828ccd133e77361cee67296fb7cbadc7a17bb\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00138-of-00195.parquet\": {\"num_bytes\": 96478432, \"checksum\": \"16c3401b554ce954d4958fe772d4abede993f104c2060fef374ff0c307b404b1\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00139-of-00195.parquet\": {\"num_bytes\": 94740084, \"checksum\": \"3695ed4ce8d0510698a10f7559209061e80840730b987e257e43ab7994e75df3\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00140-of-00195.parquet\": {\"num_bytes\": 96650714, \"checksum\": \"d40538604f390db63288d6e04abba3c9a915b14b0c25c15418bc1132683f9c12\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00141-of-00195.parquet\": {\"num_bytes\": 101867871, \"checksum\": \"90a00090aa98784e9ae3b893a7e5f2d20ad5072a06ec90f15a0672d3134b1dd7\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00142-of-00195.parquet\": {\"num_bytes\": 99662820, \"checksum\": \"b2751c0b153525b6095036b7b1419148615852a4c8b7159c90db372cb33d673c\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00143-of-00195.parquet\": {\"num_bytes\": 102238828, \"checksum\": \"f573217b678f5a2fa2facaa722088477ef3263704205d84a2bde09adec7b871b\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00144-of-00195.parquet\": {\"num_bytes\": 102533403, \"checksum\": \"46f8cc449fa524c49d39ef004be6c98e851d5ec2eaa8e17c2ca0467ff0d81572\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00145-of-00195.parquet\": {\"num_bytes\": 101040293, \"checksum\": \"f57eb8ade6773b080083fc4ef00207ec7f9d12b7904738d01b96d9df7a7961cb\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00146-of-00195.parquet\": {\"num_bytes\": 100308225, \"checksum\": \"497a2fe5aec8ae4ccd9625f6640bca632913a97d693b9087d35a6f9cfda3363a\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00147-of-00195.parquet\": {\"num_bytes\": 94805243, \"checksum\": \"2824cd17a221b063a80b76f50bf21cb728d27e743185595a613963d57992fd9d\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00148-of-00195.parquet\": {\"num_bytes\": 99379848, \"checksum\": \"c0b3afd548752e89e1116d0495c344ad22f06ae93517542181320d944503ac5a\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00149-of-00195.parquet\": {\"num_bytes\": 95601057, \"checksum\": \"da48c875d30e403201e390f195259ab01c2f880d6c0d055abac6962367b54b65\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00150-of-00195.parquet\": {\"num_bytes\": 98942213, \"checksum\": \"3ad2dc2c16817a1e600da03d954a708d6cd0b40c97ca05cbbe373c426c915ba5\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00151-of-00195.parquet\": {\"num_bytes\": 95674961, \"checksum\": \"c308e6c026a67e4fd93670f75da83b2cfaeeb12b36270750463fcc3296960fb9\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00152-of-00195.parquet\": {\"num_bytes\": 101542150, \"checksum\": \"3f4056d80f77c3fa9f0f6479b1f8361a60d8c0f6f5e554d1e10e1638b4248e12\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00153-of-00195.parquet\": {\"num_bytes\": 101690299, \"checksum\": \"0fcd96044e2fb51bbd9ece81b84316f6508da601eaecb195c1284bbf8b7fbc2a\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00154-of-00195.parquet\": {\"num_bytes\": 101247507, \"checksum\": \"f4a5d8dd3371af4384e73704d6bc8e7572228baedf1313b30a721c159e64a101\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00155-of-00195.parquet\": {\"num_bytes\": 100750517, \"checksum\": \"527e07b87f19f495e44627d34f70610f1348df757179fbe4966030496df787aa\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00156-of-00195.parquet\": {\"num_bytes\": 98466660, \"checksum\": \"c572b1aa9c93c09fd482268c2e7af1f113f753b048956a20d83383fa28e859a6\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00157-of-00195.parquet\": {\"num_bytes\": 97015771, \"checksum\": \"eb7b8e5d63a6b8cb251f32ae612b76d41c2e10e3cac50918b848eee384505080\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00158-of-00195.parquet\": {\"num_bytes\": 99567978, \"checksum\": \"e611b3b9be4c820b7e21ea9ed4afb51fbc202ab75182a46c1a64229126fdb5bd\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00159-of-00195.parquet\": {\"num_bytes\": 101337232, \"checksum\": \"d81fcbd53c1a45b55ddb13b8cfba00589a84860561cbb4217f632c66fb9e219d\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00160-of-00195.parquet\": {\"num_bytes\": 102349720, \"checksum\": \"6b1a5e5c7b8980fb47a1db9a27200d147de3fe583bce49289a67168b328b773b\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00161-of-00195.parquet\": {\"num_bytes\": 97684291, \"checksum\": \"e07bac49991a9b2194524fbaa3c3677fa8e158dd6d92adb6153ac70759546654\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00162-of-00195.parquet\": {\"num_bytes\": 98694984, \"checksum\": \"8f3e83c01b384381e13ea3a2c18f5d593b4013c9f2775985936f55efe5058e64\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00163-of-00195.parquet\": {\"num_bytes\": 100429869, \"checksum\": \"2d1493c55c2a5954f261e09194f06f5e841ebdd77cec76da859eaabb39ea30e7\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00164-of-00195.parquet\": {\"num_bytes\": 95622880, \"checksum\": \"72bb66cd5cb44bd6176c5641528a01715a0e3e8505e97101cadec75efa4350b5\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00165-of-00195.parquet\": {\"num_bytes\": 103582800, \"checksum\": \"2188152909da0577e5df13f9ea9a725c82a907ac2a513a1ace7f9c02a40aafbd\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00166-of-00195.parquet\": {\"num_bytes\": 99182897, \"checksum\": \"c07cd9fe4971121349dacb98bd41f7a84869791189cbe3c345a0d160832c2acb\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00167-of-00195.parquet\": {\"num_bytes\": 96442069, \"checksum\": \"6ac6f3fb23ec4c11830bac10ec8cca8e6a0f46025ae342717d417f98775495e2\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00168-of-00195.parquet\": {\"num_bytes\": 102991632, \"checksum\": \"11279809465ddfe7aa2bc82bae0e28652c6e43bbbdd3c0457cb1f6a9f8b41b3f\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00169-of-00195.parquet\": {\"num_bytes\": 99122587, \"checksum\": \"834d2c024a4d24e82d0c5bf67b878bc181a122dfcf8ec3638081266e2560381f\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00170-of-00195.parquet\": {\"num_bytes\": 102519243, \"checksum\": \"bc4b08e173dfd74686c858c2d77c1412dba8555e7f191d90118f700e7f2a61d3\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00171-of-00195.parquet\": {\"num_bytes\": 101920415, \"checksum\": \"7d7e121d47227065ef74e0b1010075d513d3a0d1be8b6f88eb73423f3c739880\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00172-of-00195.parquet\": {\"num_bytes\": 101031159, \"checksum\": \"56793041534cd23401359424be9c77645dedddaea90324344d5388168fe1f5a1\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00173-of-00195.parquet\": {\"num_bytes\": 97079912, \"checksum\": \"40d0532e94a94eabcaf0fe2d2d902d38537371f372e3edcd50328598caed5ee1\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00174-of-00195.parquet\": {\"num_bytes\": 97450447, \"checksum\": \"a67f412750caf5d99740f8bf9160a62ce4e220d362b55faf9ac37bdd3e7db885\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00175-of-00195.parquet\": {\"num_bytes\": 97280969, \"checksum\": \"837779a5822c200c9faa82e73d95d9a66320e1a98d32880c57e32e7469f13cd3\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00176-of-00195.parquet\": {\"num_bytes\": 98953073, \"checksum\": \"33c4fd910c88989595953308b2cece88f05f6b892a97e8faf9964f7bdd57dd6f\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00177-of-00195.parquet\": {\"num_bytes\": 100295634, \"checksum\": \"558ddc181c2ed09d84b0559317826123547ef95311d3de18a6e6d9bc632b6f20\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00178-of-00195.parquet\": {\"num_bytes\": 93569469, \"checksum\": \"e555476687cb0ba04dd363679e8e1adfc3feb08531c7f1d6756ffb96f2ec8864\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00179-of-00195.parquet\": {\"num_bytes\": 103447258, \"checksum\": \"707d47f7553b836cdbd33f62d8196861c6a5fd54302a579d72377f29338c4a74\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00180-of-00195.parquet\": {\"num_bytes\": 101680169, \"checksum\": \"b79ca4bbd902873678e65d125fa2fafa9176b0e9ad3646241dc7d489f74cd416\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00181-of-00195.parquet\": {\"num_bytes\": 102429613, \"checksum\": \"a93866d4a4d05d2c1f5aead43589907adf060c4941fe44cdc1cb26622d5c9084\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00182-of-00195.parquet\": {\"num_bytes\": 100985811, \"checksum\": \"635b1a1f8f4349e652bd6b1613e6567414180b7df97795a34a0b1f3a612eef16\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00183-of-00195.parquet\": {\"num_bytes\": 100006681, \"checksum\": \"27b573571b4ac36eaf7a833a95f17601f0d28996e73320829072e0f492f031f9\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00184-of-00195.parquet\": {\"num_bytes\": 100942100, \"checksum\": \"167934d7e5e0033676a5b97abfb02eba76fffcb944b32ff7f126b5683e078906\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00185-of-00195.parquet\": {\"num_bytes\": 95473034, \"checksum\": \"2c2580d0812dbb3a0c6bcd20bb2c8eb4be0ef718114744d53a4111fe2ae23bd4\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00186-of-00195.parquet\": {\"num_bytes\": 99736017, \"checksum\": \"8bb132b7c63442b3280c79ddb0f0078d81ce390252c3d9fe58dd67eadae01e83\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00187-of-00195.parquet\": {\"num_bytes\": 97266290, \"checksum\": \"8660a3deccd2e7856af4f9f16528e57b0326801396ef40bb102e247dd846b1cd\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00188-of-00195.parquet\": {\"num_bytes\": 102411030, \"checksum\": \"0b157b6a800f01ac12f3d8c2e4db4394295ee1c522509ff55ecd0ddfbcc1ac7e\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00189-of-00195.parquet\": {\"num_bytes\": 101124897, \"checksum\": \"9be416392b9cf7091c447255007ed3fd7a4f8556b9d7a9c0a8d60ebd764275b8\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00190-of-00195.parquet\": {\"num_bytes\": 99427113, \"checksum\": \"98e5209d1e26ac173941f12848f21ba383fe0f1a9b3c9f7c387d89ec21bfa660\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00191-of-00195.parquet\": {\"num_bytes\": 95185557, \"checksum\": \"04944cf173eb687a15adb6250fc629ca2b439cefe6e497cafa2f6245c40a4f05\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00192-of-00195.parquet\": {\"num_bytes\": 101191786, \"checksum\": \"51b7394a5c6de170df474e28068cc25fd5b1b5b8c9a0f3ee36b55544d33bcf35\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00193-of-00195.parquet\": {\"num_bytes\": 102965719, \"checksum\": \"e2d7c0e0a429702622f0faa8b8ee755b008b3a968e82eb4f4c78d786c1e66413\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/train-00194-of-00195.parquet\": {\"num_bytes\": 94367267, \"checksum\": \"6a6d03411e314b7a2b695603127f6f6c1309824dd7f6550d9f0d6150fffd8067\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00000-of-00025.parquet\": {\"num_bytes\": 99392035, \"checksum\": \"153906c03cface6ad057d928ba05fb50b858e6cd736de7f214f077f65b081c4a\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00001-of-00025.parquet\": {\"num_bytes\": 97236393, \"checksum\": \"57a463464c9e4dda3a166f608db45138f1c151b26c11acdb873ce916dfef1d4b\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00002-of-00025.parquet\": {\"num_bytes\": 102553393, \"checksum\": \"cc237ad2a644e4d867ea48c11f1ef1800a5a8f63023b4e223a3fcba0a6eb3543\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00003-of-00025.parquet\": {\"num_bytes\": 99099381, \"checksum\": \"2ff2c226821ec253ffa2284fc5ecbd7bca122f09be51b1dbb8cb16e25aca16c5\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00004-of-00025.parquet\": {\"num_bytes\": 92695260, \"checksum\": \"6a3eceb029be0261bc4e63dc1491defae7f5ebce9acbb4902cd596c9a9ae24a8\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00005-of-00025.parquet\": {\"num_bytes\": 95422177, \"checksum\": \"674124d498e04244ad9067b32dc893284e2eb745a5730742f99e351e4d83e29a\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00006-of-00025.parquet\": {\"num_bytes\": 95994458, \"checksum\": \"4e0e8561820484bcae10cfc83b8c4c5929c414d5bbfd5d986a6a12cdafcce6a8\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00007-of-00025.parquet\": {\"num_bytes\": 92521309, \"checksum\": \"1fe04f94c87cfacbcc42eab7eb91009b4123dd8b6f571c86be71d01fd5d868df\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00008-of-00025.parquet\": {\"num_bytes\": 95926731, \"checksum\": \"5785d204828bb8c972d320ca5cb4491088c0b775157dc2fdbee9ec9114951288\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00009-of-00025.parquet\": {\"num_bytes\": 101594507, \"checksum\": \"585bd5d93908f924964d455420dcb1b854f1d8b1cbce0b524d1ce6852355175a\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00010-of-00025.parquet\": {\"num_bytes\": 98693277, \"checksum\": \"e2a4ac18cd0414c79ce9751e0470c074f103c40167da7dfd3c9b104b1fe36b8f\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00011-of-00025.parquet\": {\"num_bytes\": 96651694, \"checksum\": \"499fa211730035f2035fe4180ee2b2d566e8809d3ac645ab916d79e7611b1c72\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00012-of-00025.parquet\": {\"num_bytes\": 99550139, \"checksum\": \"7e9bbd8945d370d2a7d7ccd4021e52a11e8819c7396ee91469624b6e714b3312\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00013-of-00025.parquet\": {\"num_bytes\": 95766815, \"checksum\": \"9481f39574283998a3b111f25cc3b11d49fa17edb6fe204ceed41b942d8c4fd9\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00014-of-00025.parquet\": {\"num_bytes\": 95415472, \"checksum\": \"9b279f6b88aef440e8a7e494dc5a62eb5b35b31df201d7af0eb65c9008871b3e\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00015-of-00025.parquet\": {\"num_bytes\": 93017301, \"checksum\": \"9ec8a787fc64894a4293550d79b4c16780816099e250a509a1e72c2643fe17af\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00016-of-00025.parquet\": {\"num_bytes\": 95304596, \"checksum\": \"c2fc163609b71014ebef6a9cfbdf423be2b735d88381d55f8ebbbd6fd88bfc3b\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00017-of-00025.parquet\": {\"num_bytes\": 100028386, \"checksum\": \"8629fefb8ff10bd1f596195034dc3b21f255554003db5ff8e266b4fb2817e36b\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00018-of-00025.parquet\": {\"num_bytes\": 98576761, \"checksum\": \"d489b676fb1449b5cebc486e3ddb239d4a0d4050ded41a89b4426f58e9c994d1\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00019-of-00025.parquet\": {\"num_bytes\": 96858053, \"checksum\": \"e68883a5e98c43ec96ac1f288067f2d43698a31c5a37799266bf2b3f3284eb27\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00020-of-00025.parquet\": {\"num_bytes\": 96198520, \"checksum\": \"012d70e9d9e7da1a519e17441863d6905f1b63d19aac810d3712162543cae32d\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00021-of-00025.parquet\": {\"num_bytes\": 96937764, \"checksum\": \"2b401080c9deb836a6114284496471bc5cf25e369dd45caac391cb1bd15c59d0\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00022-of-00025.parquet\": {\"num_bytes\": 95664099, \"checksum\": \"c28e8dc738fcb97579475be3bc9811d37de85e085278e2649c27c2d2852db734\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00023-of-00025.parquet\": {\"num_bytes\": 94201930, \"checksum\": \"690ec735f2dbd8d21bbafa1e3099f805116fe44bc9add624a0bfd7df469c5ddd\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/test-00024-of-00025.parquet\": {\"num_bytes\": 93893651, \"checksum\": \"df066d37de286f6632fb6e6f368b420135a24a734f49e6cf0bf81dcdb4672638\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00000-of-00025.parquet\": {\"num_bytes\": 98529457, \"checksum\": \"949bb8041e9e8a72689c474b9d9921d179fff6a14ccf914498e741916c4e9630\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00001-of-00025.parquet\": {\"num_bytes\": 97578710, \"checksum\": \"8d862ee37c9dafc78fde7e0f6197c9d5471f531cd01628078bf8b5a53caae816\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00002-of-00025.parquet\": {\"num_bytes\": 98986271, \"checksum\": \"170b4d67eff76a64237f3f55c82cbd3f7065ee8f01a1d9568d7a5858fbc5bd25\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00003-of-00025.parquet\": {\"num_bytes\": 101624201, \"checksum\": \"2417ac064ce10bde9c0822e0cf2c38e4ab68c96e9c40b5b09c505a9c31aacd4d\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00004-of-00025.parquet\": {\"num_bytes\": 94914949, \"checksum\": \"090161550f2f5ae8e35a24846e2b5191441855780721603aee9fc40a7d037974\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00005-of-00025.parquet\": {\"num_bytes\": 97203342, \"checksum\": \"1cfbed5fd375cf52d6a4b40ea4233258b7d6fc808e3d25f4cb2b12ab5382273a\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00006-of-00025.parquet\": {\"num_bytes\": 97732854, \"checksum\": \"8a3b07bc2e87aac36bb73d4d5e7b483a1bc02ed2890760fdb8767d62712a03c2\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00007-of-00025.parquet\": {\"num_bytes\": 96474873, \"checksum\": \"d93b78ed4eddbdf13874efd47a3210185631f51093854f7820213cde02a07144\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00008-of-00025.parquet\": {\"num_bytes\": 92754667, \"checksum\": \"462e9e1f9bf932afc7d19759091be49c412f9630221f17595598e193a3211994\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00009-of-00025.parquet\": {\"num_bytes\": 100032749, \"checksum\": \"194602d267bf1882ffcabeb8705f4602bd9131618f4f3cdb4413e0b6ea78b321\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00010-of-00025.parquet\": {\"num_bytes\": 99097158, \"checksum\": \"f7f056b8d93e8c6aa83b2d08d2d5a4cbdf30ead4148004101dcdaed5b321fb18\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00011-of-00025.parquet\": {\"num_bytes\": 97056747, \"checksum\": \"9587dff56bd44103ef0a371160c39ce5f43798fc1114c7890e186d3aa1b2bb5f\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00012-of-00025.parquet\": {\"num_bytes\": 94315352, \"checksum\": \"aa35c78534a92d8fe5d1ca51155395d2145ad3610db11b4e881be31d056a77b1\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00013-of-00025.parquet\": {\"num_bytes\": 96892902, \"checksum\": \"f124bd5748823876be206f1c4d6ed22c8fe9519c43701c2162cb345ee03b85e2\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00014-of-00025.parquet\": {\"num_bytes\": 97260890, \"checksum\": \"28b3d6431ffb5c40ff83d0a823c1a45dd68cd32107e027af48b45066276c260b\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00015-of-00025.parquet\": {\"num_bytes\": 95787686, \"checksum\": \"b9d8a288be5524b93be5f4883ec8eadc10b6e14eae55328d0f0d83499edfe94a\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00016-of-00025.parquet\": {\"num_bytes\": 95363214, \"checksum\": \"a2060033448b52928d4b4e9a8acb7a62c05f96a92fdbe75071e19552a1c3e4f2\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00017-of-00025.parquet\": {\"num_bytes\": 99342118, \"checksum\": \"b4775f3c25aeca71b10fd9352e53beda9672f051fce7b3c925434c51a30a851b\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00018-of-00025.parquet\": {\"num_bytes\": 100256356, \"checksum\": \"641d4e1a3cf527708399fdb772ae445e597d0a5040f5313b0ab2ab58b64ead02\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00019-of-00025.parquet\": {\"num_bytes\": 98890063, \"checksum\": \"28ddbe3907563a77cd75fd5080f11ca37c869310b1756bfe521504466e324a88\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00020-of-00025.parquet\": {\"num_bytes\": 98212209, \"checksum\": \"b1c742666940cb48461ba073305c601d560067ef44337836a481a81cdc5e069c\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00021-of-00025.parquet\": {\"num_bytes\": 101291335, \"checksum\": \"d288c37b063a459c3b060d36ac357eaa13c3dc434450ac3a35a92d67b49cfea0\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00022-of-00025.parquet\": {\"num_bytes\": 98278959, \"checksum\": \"7f30c733a8a25ed2f7f9002108e5589a9d34612bad90976e6be0775fbc2af703\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00023-of-00025.parquet\": {\"num_bytes\": 99927332, \"checksum\": \"2b359e2095be4a06bcdb8f140681dfc2490c28cec36917aa2669d2eefa704f8c\"}, \"https://huggingface.co/datasets/jwh1449/AIhub_KoSpeech_dataset2/resolve/71dd923c7ed5ac671c819db3f1769960581aff29/data/valid-00024-of-00025.parquet\": {\"num_bytes\": 98814559, \"checksum\": \"6f8aa32b745153c08d1a611f9caf9ff8b728fad6f2278acb69dd41c56bedf5a1\"}}, \"download_size\": 24334547387, \"dataset_size\": 125347837550, \"size_in_bytes\": 149682384937}\n",
    "\n",
    "\n",
    "# def download_and_verify(url, output_path, expected_checksum):\n",
    "#     if not os.path.exists(output_path):\n",
    "#         print(f\"Downloading {url} to {output_path}\")\n",
    "#         response = requests.get(url, stream=True)\n",
    "#         with open(output_path, \"wb\") as f:\n",
    "#             for chunk in response.iter_content(chunk_size=8192):\n",
    "#                 f.write(chunk)\n",
    "    \n",
    "#     # 체크섬 확인\n",
    "#     with open(output_path, \"rb\") as f:\n",
    "#         sha256_hash = hashlib.sha256()\n",
    "#         while chunk := f.read(8192):\n",
    "#             sha256_hash.update(chunk)\n",
    "#         computed_checksum = sha256_hash.hexdigest()\n",
    "    \n",
    "#     if computed_checksum != expected_checksum:\n",
    "#         raise ValueError(f\"Checksum mismatch for {output_path}: expected {expected_checksum}, got {computed_checksum}\")\n",
    "#     return output_path\n",
    "\n",
    "# download_dir = \"/home/aiuser/kospeech_parquet\"\n",
    "# os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# data_files = {\"train\": [], \"test\": [], \"valid\": []}\n",
    "# for url, info in dataset_info[\"download_checksums\"].items():\n",
    "#     split = \"train\" if \"train-\" in url else \"test\" if \"test-\" in url else \"valid\"\n",
    "#     file_name = os.path.basename(url)\n",
    "#     output_path = os.path.join(download_dir, file_name)\n",
    "#     try:\n",
    "#         download_and_verify(url, output_path, info[\"checksum\"])\n",
    "#         data_files[split].append(output_path)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to download {url}: {e}\")\n",
    "\n",
    "# # 이미 다운로드된 파일 추가\n",
    "# existing_files = [\n",
    "#     \"/home/aiuser/train-00000.parquet\",\n",
    "#     \"/home/aiuser/test-00000.parquet\",\n",
    "#     \"/home/aiuser/kospeech_parquet/valid-00000.parquet\"\n",
    "# ]\n",
    "# for f in existing_files:\n",
    "#     if os.path.exists(f):\n",
    "#         split = \"train\" if \"train-\" in f else \"test\" if \"test-\" in f else \"valid\"\n",
    "#         data_files[split].append(f)\n",
    "\n",
    "# Parquet 파일 로드\n",
    "try:\n",
    "    dataset = load_dataset(\"parquet\", data_files=data_files)\n",
    "    print(\"Dataset 객체:\")\n",
    "    print(dataset)\n",
    "    print(\"\\nTrain 스플릿:\", dataset[\"train\"])\n",
    "    print(\"Test 스플릿:\", dataset[\"test\"])\n",
    "    print(\"Valid 스플릿:\", dataset[\"valid\"])\n",
    "except Exception as e:\n",
    "    print(f\"오류: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files: 195\n",
      "Test files: 25\n",
      "Valid files: 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ddf81f5e2347989676a80e38964250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76be3ccc5be649e288f61d3de9df1c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba7983b1de241a3bbb3834dc317da6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e16a175eb6ef4ba48b7fd6bfd5f16de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d86f117fc247899e5a9019a08b76b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63c8e454db24be382c6ad46fa237e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset 객체:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_features', 'labels'],\n",
      "        num_rows: 101236\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_features', 'labels'],\n",
      "        num_rows: 12655\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['input_features', 'labels'],\n",
      "        num_rows: 12654\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# Parquet 파일이 있는 폴더\n",
    "data_dir = \"/home/aiuser/kospeech_parquet\"\n",
    "\n",
    "# 모든 .parquet 파일 목록 가져오기\n",
    "parquet_files = glob.glob(os.path.join(data_dir, \"*.parquet\"))\n",
    "\n",
    "# 스플릿별 파일 분류\n",
    "data_files = {\"train\": [], \"test\": [], \"valid\": []}\n",
    "for file_path in parquet_files:\n",
    "    file_name = os.path.basename(file_path)\n",
    "    if \"train-\" in file_name:\n",
    "        data_files[\"train\"].append(file_path)\n",
    "    elif \"test-\" in file_name:\n",
    "        data_files[\"test\"].append(file_path)\n",
    "    elif \"valid-\" in file_name:\n",
    "        data_files[\"valid\"].append(file_path)\n",
    "\n",
    "# 각 스플릿의 파일 목록 확인\n",
    "print(\"Train files:\", len(data_files[\"train\"]))\n",
    "print(\"Test files:\", len(data_files[\"test\"]))\n",
    "print(\"Valid files:\", len(data_files[\"valid\"]))\n",
    "\n",
    "# Parquet 파일 로드\n",
    "try:\n",
    "    dataset = load_dataset(\"parquet\", data_files=data_files)\n",
    "    print(\"\\nDataset 객체:\")\n",
    "    print(dataset)\n",
    "except Exception as e:\n",
    "    print(f\"오류: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502,
     "referenced_widgets": [
      "01b6e44c4aa440ada221593a7e8ee4f1",
      "2926e94adaeb4305bbf0de8a6b041181",
      "657423bf18e44ab782060bc2b9871214",
      "1e52fd5864104af7bf18fd1974588345",
      "54f9cdb4c8814748a28d1062e8d68094",
      "7c153b80baf14b5a934b59c37c60e1a9",
      "a35b374e98ef4a56b2622554382ec716",
      "592f4da84caa47babffb72e1bbbfa997",
      "a98eed090fe549ba8c891ff67b2094bf",
      "7b1a1b8799fe429f94f065b91bace924",
      "cf1feeac83b84ad98f24077444a8846a",
      "171451fadd70407abf1fc70bdf54b93f",
      "ed575f166e384a31a6aecbf46e76a444",
      "dfaeb165434b4957bf2852851a61596c",
      "53443554836c48b7a8800dfeebc190f2",
      "ce2aecaf0dfd4acfb30c5044d040f0be",
      "f8378ef6595449169a96889c1cab6dca",
      "0f228f2d9e7c4a2eb376225b5bf32197",
      "953b0c3b6af047228d699d2b98682749",
      "037437b128da471eb519f636b213b467",
      "e0860fee0d0d41e8bd50f096dbd19305",
      "07d5564596cf4749a4a50d5d21ebb024",
      "75cc9def9929418f89ccca8d7908e5e6",
      "9950825cce88426c9fc842acc03185fd",
      "b7f2aaf80d7a4e339265962fd0721f4f",
      "13539a7dafcc4d689b50bd1522e9cb38",
      "fabe5826e8484665b286ed451b082ffa",
      "273f2430d0e44423a1728de64c154e28",
      "5eefa2de3d0b4fde8285757422489cee",
      "ce1b8820b1f3469db55227d856b6d20e",
      "6a0109b9a7de4b7aa2e4834288aa91b8",
      "32ae7649ce8b4f6cb19da0820421fb7c",
      "ab3e4df837d847068cdc30482a35d2a7"
     ]
    },
    "id": "JHnjhQOd9jig",
    "outputId": "a82a35bc-52d7-4c6e-ad81-ad701e04676f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_features', 'labels'],\n",
       "        num_rows: 101236\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_features', 'labels'],\n",
       "        num_rows: 12655\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_features', 'labels'],\n",
       "        num_rows: 12654\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hub로부터 전처리가 완료된 데이터셋을 로드\n",
    "from datasets import load_dataset\n",
    "# low_call_voices_prepreocessed = load_dataset(\"jwh1449/AIhub_KoSpeech_dataset2\")\n",
    "low_call_voices_prepreocessed = dataset\n",
    "low_call_voices_prepreocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TA5n94Ux-KIw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # 인풋 데이터와 라벨 데이터의 길이가 다르며, 따라서 서로 다른 패딩 방법이 적용되어야 한다. 그러므로 두 데이터를 분리해야 한다.\n",
    "        # 먼저 오디오 인풋 데이터를 간단히 토치 텐서로 반환하는 작업을 수행한다.\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # Tokenize된 레이블 시퀀스를 가져온다.\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # 레이블 시퀀스에 대해 최대 길이만큼 패딩 작업을 실시한다.\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # 패딩 토큰을 -100으로 치환하여 loss 계산 과정에서 무시되도록 한다.\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # 이전 토크나이즈 과정에서 bos 토큰이 추가되었다면 bos 토큰을 잘라낸다.\n",
    "        # 해당 토큰은 이후 언제든 추가할 수 있다.\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-CU6c_As-MWe"
   },
   "outputs": [],
   "source": [
    "# 훈련시킬 모델의 processor, tokenizer, feature extractor 로드\n",
    "from transformers import WhisperTokenizer,  WhisperFeatureExtractor\n",
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"Korean\", task=\"transcribe\")\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Korean\", task=\"transcribe\")\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "w0a9oB-r-etg"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qAoUXkhl_V-4"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load('cer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "IWjMFm1f_akM"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # pad_token을 -100으로 치환\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # metrics 계산 시 special token들을 빼고 계산하도록 설정\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    cer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"cer\": cer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Cgfyjoxx_dHI"
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Vyz4Oq_XD4La"
   },
   "outputs": [],
   "source": [
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TCHEoEpR_hpW"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"jwh1449/whisper_small_test\",  # 원하는 리포지토리 이름을 임력한다.\n",
    "    per_device_train_batch_size=16, # 기존 16\n",
    "    gradient_accumulation_steps=1,  # 배치 크기가 2배 감소할 때마다 2배씩 증가\n",
    "    learning_rate=1e-4, # 기존 1e-5\n",
    "    warmup_steps=500, # 기존 500\n",
    "    max_steps=7000,  # epoch 대신 설정, 기존 4000\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=8, # 기존 8\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=1000,\n",
    "    eval_steps=500, # 평가 1000\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"cer\",  # 한국어의 경우 'wer'보다는 'cer'이 더 적합할 것\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=True,\n",
    "    weight_decay=0.01, # 과적합 방지\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yPm-4u0j_k6R",
    "outputId": "85f3ed15-d713-42a1-a204-c7c73ab5be05"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_117412/2876998388.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=low_call_voices_prepreocessed[\"train\"],\n",
    "    eval_dataset=low_call_voices_prepreocessed[\"valid\"],  # or \"test\"\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "M4RMamZN_lqs",
    "outputId": "5ac6a16b-f707-4b54-b0e4-2ca7061eb5e8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7000' max='7000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7000/7000 11:43:24, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Cer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.729500</td>\n",
       "      <td>0.714575</td>\n",
       "      <td>24.931713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.654300</td>\n",
       "      <td>0.679919</td>\n",
       "      <td>48.001186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.629100</td>\n",
       "      <td>0.611343</td>\n",
       "      <td>18.174103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.577000</td>\n",
       "      <td>0.571449</td>\n",
       "      <td>18.597967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.479200</td>\n",
       "      <td>0.517649</td>\n",
       "      <td>15.990061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.477500</td>\n",
       "      <td>0.483490</td>\n",
       "      <td>15.452819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.435800</td>\n",
       "      <td>0.454266</td>\n",
       "      <td>15.317038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.424617</td>\n",
       "      <td>13.046095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.396100</td>\n",
       "      <td>0.401797</td>\n",
       "      <td>12.958064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.377600</td>\n",
       "      <td>0.376812</td>\n",
       "      <td>11.797134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.392300</td>\n",
       "      <td>0.360150</td>\n",
       "      <td>11.412873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.360100</td>\n",
       "      <td>0.340604</td>\n",
       "      <td>10.823582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.202900</td>\n",
       "      <td>0.332050</td>\n",
       "      <td>10.352873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.189900</td>\n",
       "      <td>0.328336</td>\n",
       "      <td>10.196498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "/home/aiuser/miniconda3/envs/test/lib/python3.9/site-packages/transformers/modeling_utils.py:3447: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7000, training_loss=0.477365462235042, metrics={'train_runtime': 42207.0584, 'train_samples_per_second': 2.654, 'train_steps_per_second': 0.166, 'total_flos': 3.231810181103616e+19, 'train_loss': 0.477365462235042, 'epoch': 1.1061946902654867})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Z5twPxBx_pfw"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7940b85306464fba9371d23a6fe57150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/jwh1449/whisper_small_test/commit/b3cd90f615c5a9014a8af259e2cbdbbf5945bfec', commit_message='Upload tokenizer', commit_description='', oid='b3cd90f615c5a9014a8af259e2cbdbbf5945bfec', pr_url=None, repo_url=RepoUrl('https://huggingface.co/jwh1449/whisper_small_test', endpoint='https://huggingface.co', repo_type='model', repo_id='jwh1449/whisper_small_test'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs = {\n",
    "    \"dataset_tags\": \"jwh1449/AIhub_KoSpeech_dataset2\",\n",
    "    \"dataset\": \"AIhub_KoSpeech_dataset2\",  # a 'pretty' name for the training dataset\n",
    "    \"dataset_args\": \"config: ko, split: valid\",\n",
    "    \"language\": \"ko\",\n",
    "    \"model_name\": \"whisper_small_test\",  # a 'pretty' name for your model\n",
    "    \"finetuned_from\": \"openai/whisper-small\",\n",
    "    \"tasks\": \"automatic-speech-recognition\",\n",
    "    \"tags\": \"hf-asr-leaderboard\",\n",
    "}\n",
    "trainer.push_to_hub(**kwargs)\n",
    "processor.push_to_hub(\"jwh1449/whisper_small_test\")\n",
    "tokenizer.push_to_hub(\"jwh1449/whisper_small_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-i-7eUBpI6T"
   },
   "outputs": [],
   "source": [
    "!mkdir -p /content/drive/MyDrive/whisper_checkpoint\n",
    "!cp -r jwh1449/whisper_base_test/checkpoint-4000 /content/drive/MyDrive/whisper_checkpoint/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xcJfieUgkRp6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c194ab916b1c4890a8d85fb24876e314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaddf19cbbe3426c884744b752413764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fddc725eba3c4b40abd224b97434389c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/3.85k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea737e71973a401da17df90860b9ad4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/356 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f47341598714625b85c10f672bf3b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ef288676d943e5bc33686a7ba38b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537d876a2f3147408e4f2db2cc985fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "410a1ef69967414693551026b5945d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30ca67a92de42c690f27e420a2e8481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6133c418af47410a8e83c49a097c7f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 파인 튜닝한 모델을 로드\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor, WhisperFeatureExtractor, WhisperTokenizer\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"jwh1449/whisper_small_test\")\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"jwh1449/whisper_small_test\")\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"jwh1449/whisper_small_test\", language=\"Korean\", task=\"transcribe\")\n",
    "processor = WhisperProcessor.from_pretrained(\"jwh1449/whisper_small_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "91rMeEC8qXn-"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "J5Ss0qpnkWp5"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"jwh1449/whisper_base_eval\",  # 원하는 리포지토리 이름을 임력한다.\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=1,  # 배치 크기가 2배 감소할 때마다 2배씩 증가\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    max_steps=4000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"cer\",  # 한국어의 경우 'wer'보다는 'cer'이 더 적합할 것\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=False,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fYpr9p6oka4Z",
    "outputId": "7fca4275-5c15-40c1-e0ce-edd55897b15b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=low_call_voices_prepreocessed[\"train\"],\n",
    "    eval_dataset=low_call_voices_prepreocessed[\"test\"],  # for evaluation(not validation)\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "id": "XKTwuEPVkbrA",
    "outputId": "d304fd30-4aef-4e1d-f71d-811a8792e56c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3282397389411926,\n",
       " 'eval_model_preparation_time': 0.0025,\n",
       " 'eval_cer': 10.446998252348047,\n",
       " 'eval_runtime': 2174.9361,\n",
       " 'eval_samples_per_second': 5.819,\n",
       " 'eval_steps_per_second': 0.727}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnlptutti\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmetrics\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WhisperForConditionalGeneration, WhisperProcessor\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import random\n",
    "import torch\n",
    "import librosa\n",
    "import nlptutti as metrics\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 디버그 로그 활성화 (CentOS 문제 추적용)\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "random.seed(42)\n",
    "\n",
    "# 모델과 프로세서 로드\n",
    "try:\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(\"jwh1449/whisper_small_test\")\n",
    "    processor = WhisperProcessor.from_pretrained(\"jwh1449/whisper_small_test\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model/processor: {e}\")\n",
    "    print(\"Ensure ~/.cache/huggingface/hub is cleared and network is accessible.\")\n",
    "    exit(1)\n",
    "\n",
    "# generation_config 설정\n",
    "model.generation_config.forced_decoder_ids = None\n",
    "\n",
    "# 데이터셋 로드 (최대 100개 샘플 선택)\n",
    "dataset = load_dataset(\"jwh1449/AIhub_foreign_dataset2\", split=\"train\")\n",
    "selected_samples = random.sample(list(range(len(dataset))), min(100, len(dataset)))\n",
    "\n",
    "cer_list = []\n",
    "\n",
    "# 선택된 샘플 처리\n",
    "for idx in selected_samples:\n",
    "    item = dataset[idx]\n",
    "    audio = item[\"audio\"][\"array\"]  # 오디오 데이터\n",
    "    sr = item[\"audio\"][\"sampling_rate\"]  # 샘플레이트\n",
    "    reference_text = item[\"transcription\"]  # 정답 텍스트\n",
    "\n",
    "    print(f\"Processing sample {idx + 1}/{len(selected_samples)}\")\n",
    "\n",
    "    # 오디오 처리\n",
    "    if sr != 16000:\n",
    "        audio = librosa.resample(audio, orig_sr=sr, target_sr=16000)\n",
    "        sr = 16000\n",
    "\n",
    "    input_features = processor(audio, sampling_rate=sr, return_tensors=\"pt\").input_features\n",
    "\n",
    "    # 음성 인식\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            input_features,\n",
    "            language=\"ko\",\n",
    "            task=\"transcribe\"\n",
    "        )\n",
    "\n",
    "    asr_text = processor.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # CER 계산\n",
    "    cer_result = metrics.get_cer(reference_text, asr_text)\n",
    "    cer = cer_result['cer']\n",
    "    cer_list.append(cer)\n",
    "\n",
    "    print(f\"CER: {cer:.4f}\")\n",
    "    print(f\"Transcription: {asr_text}\")\n",
    "    print(f\"Reference: {reference_text}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# 평균 CER 출력\n",
    "if cer_list:\n",
    "    avg_cer = sum(cer_list) / len(cer_list)\n",
    "    print(f\"\\nAverage CER: {avg_cer:.4f}\")\n",
    "else:\n",
    "    print(\"No CER data available.\")\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "urM-cLfrS69n",
    "outputId": "1775e247-1e11-4b52-c02f-5b66f18cc50d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 00152-F-94-ZH-A-LAR027-0025203.wav\n",
      "CER: 0.0526\n",
      "Transcription: 담배를 피우는 사람 수가 매년 증가하고 있다.\n",
      "Reference: 아 담배를 피우는 사람 수가 매년 증가하고 있다.\n",
      "--------------------------------------------------\n",
      "Processing: 05388-F-1-JA-A-ATQ020-1777744.wav\n",
      "CER: 0.0952\n",
      "Transcription: 이 시험이 끝나면 친구랑 놀라고 싶습 놀고 싶습니다.\n",
      "Reference: 이 시험이 큰나면 친구란 놀라고 싶습 놀고 싶습니다.\n",
      "--------------------------------------------------\n",
      "Processing: 07111-F-94-ZH-A-PDT003-1592385.wav\n",
      "CER: 0.8441\n",
      "Transcription: 선배님, 죄송하는데 제가 단주 제주해야 하는 과제에 있어서 제 노트북 비가 들릴 수 없는 것 같아요. 왜냐하면 제가 제주해야 하는 과제는 새로운 프로젝트로 만들어야 해서 제 노트북 비가 들릴 수 있는 것 같아요. 그래서 제가 다른 과제에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트에 대한 새로운 프로젝트�에 대한 새로운 프로젝트북.\n",
      "Reference: 선배님 죄송한데 제가 다음 주 제출해야 하는 과제 몇 개 있어서 제 노트북 빌려 드릴 수 없는 것 같아요. 왜냐하면 제가 제출해야 하는 과제는 새로운 프로젝트로 만들어야 할 해서 다른 컴퓨터를 사용해도 안 되는 것 같아요. 그리고 제가 다른 컴퓨터를 빌려도 자기 집에 다 주고 갈 수 없어서 과제를 제 때 제 시간을 제조할 수 없는 것 같아요. 너무 죄송합니다. 이해할 수 있으면 감사합니다.\n",
      "--------------------------------------------------\n",
      "Processing: 08269-F-0-JA-B-ATQ006-2161050.wav\n",
      "CER: 0.0000\n",
      "Transcription: 제가 좋아하는 음식은 비빔밥이에요.\n",
      "Reference: 제가 좋아하는 음식은 비빔밥이에요.\n",
      "--------------------------------------------------\n",
      "Processing: 02034-F-96-ZH-A-SPT006-0476496.wav\n",
      "CER: 0.7488\n",
      "Transcription: 네 제가 대학교 때 한 대 수업에 지각했어요. 그때 여덟시에 수업인데 근데 그때 알람을 들이지 않았고 그냥 자버렸어요. 거의 다 여덟시에 됐고 제 룸에이츠가 저한테 전화가 왔어요. 제가 전화가 바뀌고 이제 거의 다 여덟시가 됐구나 그때 너무 당황했고 근데 제가 그 룸에이츠가 저한테 전화가 왔어요. 제가 그 룸에이츠가 제가 그 룸에이츠가 저한테 전화가 바뀌었어요. 제가 그 룸에이츠가 제가 그 룸에이츠가 제가 그 룸에이츠가 제가 그 룸에 이어갔어요. 제가 그 룸에이츠가 제가 그 룸에 이어갔어요. 제가 그 룸에 이어갔어요. 제가 그 룸에 이어갔어요. 제가 그 룸에 이어갔어요. 제가 그 룸에 이어갔어요. 제가 그 룸에 이어갔어요. 제가 그 룸에 이어갔어요. 제가 그 룸에 이어갔어요. 제가 그 룸에 이어갔어요. 제가 그 룸에 이어갔어요. 제가 그 룸에 이어갔어요. 제가 그 룸에 이어갔어요. 제가 그 룸에 이어갔어요. 제가 그 룸에 이어갔어요. 제가 그 룸에 이어갔어요. 제가 그 룸에 이어갔어요. 제가 그 룸에 이어갔어요. 제가 그 룸에 이어갔어요. 제가 그 룸에 이어갔어요. 제가 그 룸에 이어가. 제가 그 룸에 이어갔어요. 제가 그 룸에 이어갔어요. 제가 그 룸에 이어가. 제가 그 룸에 이어.\n",
      "Reference: 제가 대학교 때 한때 수업에 지각했어요. 그때 8시에 수업인데 근데 그때 알람을 드리지 않았고 그냥 자버렸어요. 거의 다 8시에 되었고 제 룸메이트가 저한테 전화가 왔어요. 제가 전화가 받게 되고 이제 거의 다 8시가 됐구나 그때 너무 당황했고 급하게 세수하고 정리하고 기숙사에서 나갔어요. 교실에 도착하다 보니 그때 이미 8시 반이 거의 다 되었어요. 수업이 거의 다 끝나고 그때 너무 민망하고 창 창피하고 미안했어요. 그래서 그때 선생님께 사과를 드리고 앞으로 이런 일 절대 없을 거라 이렇게 말하고 그 기억은 아직도 기억이 남아 있어요.\n",
      "--------------------------------------------------\n",
      "Processing: 02178-F-0-JA-A-LAR011-0536305.wav\n",
      "CER: 0.0000\n",
      "Transcription: 아이가 키우던 개를 잃어버려서 슬퍼해요.\n",
      "Reference: 아이가 키우던 개를 잃어버려서 슬퍼해요.\n",
      "\n",
      "--------------------------------------------------\n",
      "Processing: 02310-F-97-ZH-A-EIG001-0638201.wav\n",
      "CER: 0.3054\n",
      "Transcription: 어 지금 이 방에 생일 파티를 열리고 있습니다. 생일 파티의 주인공과 여자친구는 달콤하게 같이 케이크를 먹고 있습니다. 어 생일 파티의 주인공의 친구 중에 남자 한 명와 남자 한 명과 여자 두 명이 같이 신나게 노래 들으면서 춤을 추고 있습니다. 어 나머지 친구는 남자 세 명와 여자 두 명이 같이 춤을 추고 있습니다. 어 나머지 친구는 여자 두 명이 같이 춤을 추고 있습니다. 어 나머지 친구는 여자 두 명이 같이 춤을 추고 있습니다.\n",
      "Reference: 지금 이 방에 세일 파티를 열리고 있습니다. 생일 파티의 주인공과 여자 친구는 달콤하게 같이 케이크를 먹고 있습니다. 생일 파티의 주인공의 친구 중에 남자 한 명과 남자 한 명과 여자 두 명이 같이 신나게 노래 들으면서 춤을 추고 있습니다. 나머지 친구는 남자 세 명와 세 명과 여자 한 명이 책상에 노릇 안고 케 카드 케 카드 게임을 하고 있습니다. 책상 위에 음식이 많이 있습니다.\n",
      "--------------------------------------------------\n",
      "Processing: 03932-F-98-ZH-A-ATQ028-0833200.wav\n",
      "CER: 0.8301\n",
      "Transcription: 집을 구할 때 가장 중요하게 생각하는 것은 아무래도 집 위 교통이 편리한 걸 제일 많이 볼 것 같아요. 왜냐하면 아무래도 집이랑 교통이 편리해야 학교에 갈 때거나 도서관에 갈 때거나 그런 많이 걸을 때는 그 소도 바로 버스를 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타고 버스 타\n",
      "Reference: 집을 구할 때 가장 중요하게 생각하는 것은 아무래도 집 위 교통이 편리한가를 제일 많이 볼 것 같아요. 왜냐면 아무래도 집이랑 교통이 편리해야 뭐 학교에 갈 때거나 도서관에 갈 때거나 그런 많이 걸지 않고서도 바로 버스 같은거를 탈 수 있으니까 교통이 편리한지를 제일 크게 볼 것 같아요.\n",
      "--------------------------------------------------\n",
      "Processing: 08170-F-3-JA-B-LAR002-1749478.wav\n",
      "CER: 0.0000\n",
      "Transcription: 책이 책상 위에 있다.\n",
      "Reference: 책이 책상 위에 있다.\n",
      "--------------------------------------------------\n",
      "Processing: 06375-M-95-ZH-A-LAR021-2114742.wav\n",
      "CER: 0.0625\n",
      "Transcription: 내 친구는 항상 옆지 아이 셋을 덜 빠진다.\n",
      "Reference: 내 친구는 항상 옆집 아이 셋을 덜 빠진다.\n",
      "--------------------------------------------------\n",
      "Processing: 09299-F-0-JA-A-ATQ017-2051267.wav\n",
      "CER: 0.0000\n",
      "Transcription:  어느 정도 계획을 세워두는 게 개인적으로 중요하다고 생각합니다.\n",
      "Reference: 어느 정도 계획을 세워두는 게 개인적으로 중요하다고 생각합니다.\n",
      "\n",
      "--------------------------------------------------\n",
      "Processing: 08263-F-80-JA-A-ATQ021-2070745.wav\n",
      "CER: 0.1071\n",
      "Transcription: 여러분 황 안에 무엇이 있어요. 황 안에 모습을 자세하게 묘사해 주세요.\n",
      "Reference: 여러분 황간에 무엇이 있어요. 황간의 모습을 자세하게 묘사해 주세요.\n",
      "--------------------------------------------------\n",
      "Processing: 00809-F-96-ZH-A-ATQ003-0183246.wav\n",
      "CER: 0.0909\n",
      "Transcription: 제 생일은 치월 구일이에요.\n",
      "Reference: 제 생일은 칠월 구일이에요.\n",
      "--------------------------------------------------\n",
      "Processing: 00840-F-88-ZH-A-LAR019-0188197.wav\n",
      "CER: 0.0000\n",
      "Transcription: 사람들은 주택 가격이 떨어지기를 바란다.\n",
      "Reference: 사람들은 주택 가격이 떨어지기를 바란다.\n",
      "--------------------------------------------------\n",
      "Processing: 00470-M-2-ZH-A-ATQ028-0101900.wav\n",
      "CER: 0.0517\n",
      "Transcription: 저는 집을 구할 때 가장 중요하게 생각하는 게 주변 시설 환경이 입니다. 왜냐하면 집 근처에 모든 실소이 다 있으면 뭐든지 다 편하게 할 수 있습니다.\n",
      "Reference: 저는 집을 구할 때 가장 중요하게 생각하는게 주빈 시설 환경리입니다. 왜냐하면 집 근처에 모든 실손이 다 있으면 뭐든지 다 편하게 할 수 있습니다.\n",
      "--------------------------------------------------\n",
      "Processing: 01369-F-92-ZH-A-LAR013-0334229.wav\n",
      "CER: 0.0000\n",
      "Transcription: 동물을 키울 수 있는 크고 좋은 집에서 살고 싶어.\n",
      "Reference: 동물을 키울 수 있는 크고 좋은 집에서 살고 싶어.\n",
      "--------------------------------------------------\n",
      "Processing: 02224-F-97-JA-A-LAR006-0528131.wav\n",
      "CER: 0.0000\n",
      "Transcription: 그 사람이 운전을 할 것 같지 않아.\n",
      "Reference: 그 사람이 운전을 할 것 같지 않아.\n",
      "--------------------------------------------------\n",
      "Processing: 07645-F-93-ZH-A-SPT006-1752470.wav\n",
      "CER: 0.5657\n",
      "Transcription: 예전에 일했던 경험이 있어요. 교태 금으라서 반 여덜시부터 아침 여덜시 까지 일을 해야 하는데 제가 늦잠을 자서 지각했어요. 그때 겨울 겨울이라서 그런 거 너무 힘들었어요. 그래서 교태 교수님한테 미안하다고 말했어요. 근데 교수님한테 미안한다고 말했어요. 근데 교수님한테 미안한다고 말했어요.\n",
      "Reference: 예전에 일했던 경험이 있어요. 교대 근 근무라서 밤 여덟시 부터 아침 여덟시 까지 일을 해야 하는데 제가 늦잠을 자서 지각했어요. 그때 겨울 겨울이라서 그런지 모르지만 너무 따뜻 이불 안에서 너무 따뜻해서 지각했어요. 그래서 그 친구와 동료들은 저한테 빠 바로 전화해서 깜짝 놀랐고 빨리 나갔어요. 빨리 나갔고 회사 같이 갔어요. 그런데 그 이후에 그 이후에 이미 지각 핸 한 것을 알고 있으니까 그 매니저한테 사과하고 다시 일하 일을 했어요.\n",
      "--------------------------------------------------\n",
      "Processing: 05832-F-98-ZH-A-ATQ026-1548231.wav\n",
      "CER: 0.0000\n",
      "Transcription: 친구가 건강을 중요하게 생각해요. 그 친구는 매일 운동하고 건강한 음식만 먹어요.\n",
      "Reference: 친구가 건강을 중요하게 생각해요. 그 친구는 매일 운동하고 건강한 음식만 먹어요.\n",
      "--------------------------------------------------\n",
      "Processing: 02275-F-1-ZH-A-PDT001-0541215.wav\n",
      "CER: 0.7515\n",
      "Transcription: 솔직히 내가 생각할 때는 좀 더 한국 사람들이랑 소통해야 돼. 그래서 언어 환경이 좀 더 접근할 수 있는 것 같애. 원어민들이랑 같이 얘기하고 있을 때 좀 더 깊게 얘기하면 좀 더 생 머리에서 내에 내다가 생각하고 좀 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더.\n",
      "Reference: 솔직히 내가 생각 할 때는 좀 더 한국 사람들이랑 소통해야 돼 그래서 언어 환경이 좀 더 접근할 수 있는 것 같애. 원어민들이랑 같이 얘기하고 있을 때 좀 더 깊게 얘기하면 좀 더 생 머리에서 뇌 뇌 에다가 생각하고 좀 더 도움이지 않을까 싶어. 그래서 또 혹시 몰라도 원어민을 원어민 친구들이랑 소통을 못하고 있을 때면 좀 더 티비 보다가 아니면 예능 리얼리티 보다가 좀 더 한국 말을 더 능숙하게 들을 수 있을 거예요. 그래서 네 듣는 게 보다.\n",
      "--------------------------------------------------\n",
      "Processing: 02222-M-97-ZH-A-LAR027-0532317.wav\n",
      "CER: 0.0000\n",
      "Transcription: 담배를 피우는 사람 수가 매년 증가하고 있다.\n",
      "Reference: 담배를 피우는 사람 수가 매년 증가하고 있다.\n",
      "--------------------------------------------------\n",
      "Processing: 00920-F-99-JA-A-SSO002-0248718.wav\n",
      "CER: 0.1231\n",
      "Transcription: 저는 소셜 네트워크 서비스가 사람들의 관계를 더 가깝게 한다는 의견에 동의합니다. 왜냐하면 제가 실제로 소셜 네트워크 서비스를 통해서 사람들과 감계가 가까워졌기 때문입니다. 그리고 소셜 네트워크 서비스를 통해서 그 사람과 좋아하는 것을 교환하거나 이야기도 할 수 있고 전화도 할 수 있어서 저는 동의합니다.\n",
      "Reference: 저는 서셜 network 서비스가 사람들의 관계를 더 가깝게 한다는 의견에 동의합니다. 왜냐하면 제가 실제로 소셜네트웍스 서비스를 통해서 사람들과 관계가 가까워졌기 때문입니다. 그리고 소셜 네트웍그 서비스를 통해서 그 사람과 좋아하는 것을 교환하거나 이야기도 할 수 있고 전화도 할 수저는 동의합니다. \n",
      "--------------------------------------------------\n",
      "Processing: 00409-F-96-ZH-A-LAR004-0086873.wav\n",
      "CER: 0.0000\n",
      "Transcription: 그 사람은 매일 샤워를 한다.\n",
      "Reference: 그 사람은 매일 샤워를 한다.\n",
      "--------------------------------------------------\n",
      "Processing: 07472-F-89-ZH-A-ATQ016-1665235.wav\n",
      "CER: 0.0000\n",
      "Transcription: 한국 음식 중에 삼겹살이 제일 맛있어요.\n",
      "Reference: 한국 음식 중에 삼겹살이 제일 맛있어요.\n",
      "--------------------------------------------------\n",
      "Processing: 00759-F-78-JA-A-LAR017-0172687.wav\n",
      "CER: 0.0000\n",
      "Transcription: 내가 지금 만난 사람은 재미가 있다.\n",
      "Reference: \n",
      "내가 지금 만난 사람은 재미가 있다.\n",
      "--------------------------------------------------\n",
      "Processing: 02352-F-1-JA-A-LAR003-0591062.wav\n",
      "CER: 0.0000\n",
      "Transcription: 이 도시는 도로가 넓다.\n",
      "Reference: 이 도시는 도로가 넓다.\n",
      "--------------------------------------------------\n",
      "Processing: 09006-F-2-ZH-A-LAR004-1997724.wav\n",
      "CER: 0.0000\n",
      "Transcription: 그 사람은 매일 샤워를 한다.\n",
      "Reference: 그 사람은 매일 샤워를 한다.\n",
      "--------------------------------------------------\n",
      "Processing: 10242-F-91-ZH-A-LAR009-2468992.wav\n",
      "CER: 0.0000\n",
      "Transcription: 나는 행복하게 끝나는 영화가 좋다.\n",
      "Reference: 나는 행복하게 끝나는 영화가 좋다.\n",
      "--------------------------------------------------\n",
      "Processing: 09212-F-1-JA-A-SPT007-2089004.wav\n",
      "CER: 0.3778\n",
      "Transcription: 기억에 남은 시험은 일본에서 음시한 영어 시험이에요. 미국인 선생님하고 같이 영어로 말하기 연습도 하고 시험 데뷔를 위해 모의겨사 문제집을 사서 공부했어요. 미국인 선생님이랑 연습했을 때 하고 싶은 말을 영어로 정하기 전할 수 없었고 선생님 앞에서 눈물이 나왔어요. 그때 선생님이 말하기 연습하고 나서는 영어는 좀 어려웠어요. 하지만 결과는 나쁘지 않지만 그래도 결과가 나쁘지 않아서 그래서 결과가 나쁘지 않아서 그래서 너무 어려웠어요.\n",
      "Reference: 기억에 남은 시험은 일본에서 응시한 영어 시험이에요. 미국인 선생님하고 같이 영어로 말하기 연습도 하고 시험대비를 위해 모의고사 문제집을 사서 공부했어요. 미국인 선생님이랑 연습했을 때 하고 싶은 말을 영어로 정확히 전할 수 없었고 선생님 앞에서 눈물이 나왔어요. 그때 선생님이 너라면 할 수 있다고 해주셔서 힘이 났어요.\n",
      "--------------------------------------------------\n",
      "Processing: 00808-F-3-ZH-A-LAR018-0182129.wav\n",
      "CER: 0.0588\n",
      "Transcription: 나는 고기 요리만 시키고 야채를 안 먹는다.\n",
      "Reference: 나는 곡기 요리만 시키고 야채를 안 먹는다.\n",
      "--------------------------------------------------\n",
      "Processing: 01359-F-96-ZH-A-LAR028-0430864.wav\n",
      "CER: 0.0000\n",
      "Transcription: 시험은 당신이 말한 것만큼 어렵지 않았어요.\n",
      "Reference: 시험은 당신이 말한 것만큼 어렵지 않았어요.\n",
      "--------------------------------------------------\n",
      "Processing: 02305-F-99-ZH-A-ATQ005-0634518.wav\n",
      "CER: 0.1429\n",
      "Transcription: 중국 사람이에요.\n",
      "Reference: 중구 사람이에요.\n",
      "--------------------------------------------------\n",
      "Processing: 01245-F-96-ZH-A-LAR007-0289623.wav\n",
      "CER: 0.1429\n",
      "Transcription: 저녁하라라를 하고 나서 잠을 잔다.\n",
      "Reference: 저녁 하하를 하고 나서 잠을 잔다.\n",
      "--------------------------------------------------\n",
      "Processing: 00467-F-97-ZH-A-LAR023-0100355.wav\n",
      "CER: 0.0000\n",
      "Transcription: 나는 외출하기 전까지 방 청소를 끝내야 한다.\n",
      "Reference: 나는 외출하기 전까지 방 청소를 끝내야 한다.\n",
      "--------------------------------------------------\n",
      "Processing: 02043-F-97-ZH-A-SPT001-0478929.wav\n",
      "CER: 0.4307\n",
      "Transcription: 한국 드라마를 좋아해서 한국 여행 여학학려고 하는데요. 그래서 한국어 공부를 시작하게 되었어요. 한국어 공부할 때 특히 제일 쉬지만 말하기 제일 어려워요. 앞으로 한국어 공부 계회 아직도 많이 연습하고 싶어요. 앞으로 한국어 공부 계획은 제가 한국어 공부 계획이 제일 어려워요. 앞으로 한국어 공부 계획은 한국어 공부 계획이 제일 어려워요.\n",
      "Reference: 한국 드라마를 좋아해서 한국 여혀 여하하려고 하는데요. 그래서 한국어 공부를 시작하게 되었어요. 한국어 공부할 때 튿기 제일 쉽지만 말하기 제일 어려워요. 앞으로 한국어 공부 계회 아직 생각이 안 나와요. 아마 그 한구 드라마 많이 바고 한국 노래 많이 들면서 공부 할 것 같아요.\n",
      "--------------------------------------------------\n",
      "Processing: 06759-M-93-ZH-A-LAR021-1502661.wav\n",
      "CER: 0.1875\n",
      "Transcription: 내 친구는 항상 옆집 아이 셋을 돌반진다.\n",
      "Reference: 내 친구는 항성 옆지 아이 셋슬 돌반진다.\n",
      "--------------------------------------------------\n",
      "Processing: 08861-F-95-ZH-A-ATQ014-1996415.wav\n",
      "CER: 0.0417\n",
      "Transcription: 저는 요리하기 좋아 좋아해서 집에서 중국 요리를 자주 해요.\n",
      "Reference: 저는 요리하기 좋아 좋아해서 집에서 중구 요리를 자주해요.\n",
      "--------------------------------------------------\n",
      "Processing: 07901-F-94-ZH-A-ATQ019-1705548.wav\n",
      "CER: 0.0000\n",
      "Transcription: 콩스트 보러 가고 싶어요.\n",
      "Reference: 콩스트 보러 가고 싶어요.\n",
      "--------------------------------------------------\n",
      "Processing: 07285-M-97-ZH-B-SPT003-1573640.wav\n",
      "CER: 0.1687\n",
      "Transcription: 저는 제일 기억에 남는 모임은 주말에 태권도를 임습하고 나서 친구들이랑 보고끼 먹던 모임 모임이에요. 태권도를 같이 하는 친구와 같이 영화를 보고 문화 분이 뭐하고요요하고 친구와 일에 대해 얘기했어요.\n",
      "Reference: 저는 제이 기억에 남는 모임은 주말에 태권도를 연습하고 나서 친구들이랑 뽀곡이 어떤 모임 모임에요. 태권도를 같이 하는 친구와 같이 영화를 보고 문화 분 모허 교류하고 친구와 일에 대해 얘기 했어요.\n",
      "--------------------------------------------------\n",
      "Processing: 03062-M-97-ZH-A-ATQ028-0686598.wav\n",
      "CER: 0.0000\n",
      "Transcription: 집을 구할 때는 가장 중요하게 생각하는 것은 햇빛입니다. 햇빛이 있어야 아침을 알고 일어날 수 있고 그리고 햇빛이 있어야 사람은 우울해지지 않을 것 같습니다. 예전에 햇빛이 들어오지 않은 집에 살아봤는데 정말 우울해진 적이 있었습니다.\n",
      "Reference: 집을 구할 때는 가장 중요하게 생각하는 것은 햇빛입니다. 햇빛이 있어야 아침을 알고 일어날 수 있고 그리고 햇빛이 있어야 사람은 우울해지지 않을 것 같습니다. 예전에 햇빛이 들어오지 않은 집에 살아봤는데 정말 우울해진 적이 있었습니다.\n",
      "--------------------------------------------------\n",
      "Processing: 09132-F-1-JA-B-SPT002-2104413.wav\n",
      "CER: 0.3404\n",
      "Transcription: 저는 지난주에 인터넷에서 캔들을 샀는데 그 캔들이 아주 마음에 들지 않았습니다. 왜냐하면 제가 캔들 사진을 봤을 때는 연한 핑크여서 아주 마음에 들어서 샀는데 실제로 물건이 더 작게서 확인해 보니 색깔이 다른 거예요. 연한 핑크 아닌 호빈크여서 제가 생각하던 색깔이 아니어서 마음에 들지 않았습니다. 하지만 이미 돈을 벌고 싶습니다.\n",
      "Reference: 저는 지난주에 인터넷에서 캔들을 샀는데 그 캔들이 아주 마음에 들지 않았습니다. 왜냐하면 제가 캔들 사진을 봤을 때는 요난 핑크여서 아주 마음에 들어서 샀는데 실제로 물건이 도착해서 확인해 보니 색깔이 다른 거예요. 요난 핑크가 아닌 헛핑크여서 제가 생각하던 색깔이 아니어서 마음에 들지 않았습니다. 하지만 이미 돈을 주고 샀기 때문에 그년 내버려 두지는 않았고 그 캔들을 사용했습니다. 그리고 빨리 사용하면 눈앞에 보이지 안 않아서 좋을 거라고 생각했습니다.\n",
      "--------------------------------------------------\n",
      "Processing: 01367-F-1-ZH-A-SSO002-0463197.wav\n",
      "CER: 0.6396\n",
      "Transcription: 요즘에 sns를 통해 저이랑 좀 어린 친구도 쉽게 연락 연결할 수 있는데 근데 친구가 너무 많아서 자주 연락하지 못하는 친구도 있습니다. sns를 편해하지만 친구도 자주 연락하고 싶습니다. 그래서 sns를 통해 연락하고 싶습니다. 그래서 sns를 통해 연락하고 싶습니다.\n",
      "Reference: 요즘에 sns를 통해 저 나 좀 어린 친구도 쉽게 연락 연결할 수 있는데 근데 친구가 너무 많아서 자주 연락하지 못하는 친구도 있습니다. sns를 편해 하지만 진정한 친구가 찾기 좀 힘들어요. 요즘에 다 메시지로 보내고 통화가 거의 안 돼서 아마 진절한 말하기도 힘들다고 생각합니다. 그리고 요즘에 사람들이 다 인스타그램 에서 자기 생활을 보내고 다른 사람한테 좀 자랑스러운 자랑하는 승가도 있습니다. 진정 진실한 생활이 맞았는지도 아닌다고 생각했습니다. 그리고 옆에 친구도 어느 생활을 제가 볼 수 있어서 어느 정도의 좀 위험한 다고 생각합니다.\n",
      "--------------------------------------------------\n",
      "Processing: 01749-M-97-ZH-A-LAR021-0380262.wav\n",
      "CER: 0.2500\n",
      "Transcription: 내 친구는 항상 옆집 아이 했을 돌봐지도.\n",
      "Reference: 내 친구는 항상 옆집 아이 세스 돌봤지.\n",
      "--------------------------------------------------\n",
      "Processing: 02043-F-97-ZH-A-ATQ018-0479570.wav\n",
      "CER: 0.0000\n",
      "Transcription: 시간이 있을 때 보통 드라마를 보 봐요.\n",
      "Reference: 시간이 있을 때 보통 드라마를 보 봐요.\n",
      "--------------------------------------------------\n",
      "Processing: 02949-F-99-ZH-A-LAR019-0695765.wav\n",
      "CER: 0.0000\n",
      "Transcription: 사람들은 주택 가격이 떨어지기를 바란다.\n",
      "Reference: 사람들은 주택 가격이 떨어지기를 바란다.\n",
      "--------------------------------------------------\n",
      "Processing: 02264-F-99-ZH-A-LAR006-0530965.wav\n",
      "CER: 0.1333\n",
      "Transcription: 그 사람은 원절을 하지 않을 거지 않아.\n",
      "Reference: 그 사람은 운전을 하지 않을 거지 않아.\n",
      "--------------------------------------------------\n",
      "Processing: 07625-F-87-JA-B-LAR012-1666079.wav\n",
      "CER: 0.0000\n",
      "Transcription: 그 식당은 음식 맛이 좋다고 한다.\n",
      "Reference: 그 식당은 음식 맛이 좋다고 한다.\n",
      "--------------------------------------------------\n",
      "Processing: 01722-F-99-ZH-A-LAR007-0367049.wav\n",
      "CER: 0.0000\n",
      "Transcription: 저녁 식사를 하고 나서 잠을 잤다.\n",
      "Reference: 저녁 식사를 하고 나서 잠을 잤다.\n",
      "--------------------------------------------------\n",
      "Processing: 06375-M-95-ZH-A-LAR028-2114941.wav\n",
      "CER: 0.0000\n",
      "Transcription: 시험은 당신이 말한 것만큼 어렵지 않았어요.\n",
      "Reference: 시험은 당신이 말한 것만큼 어렵지 않았어요.\n",
      "--------------------------------------------------\n",
      "Processing: 05807-F-0-ZH-A-ATQ011-1201821.wav\n",
      "CER: 0.0000\n",
      "Transcription: 오늘 저녁에 국수를 먹을 거예요.\n",
      "Reference: 오늘 저녁에 국수를 먹을 거예요.\n",
      "--------------------------------------------------\n",
      "Processing: 01592-F-2-ZH-A-LAR011-0519814.wav\n",
      "CER: 0.0000\n",
      "Transcription: 아이가 키우던 개를 잃어버려서 슬퍼해요.\n",
      "Reference: 아이가 키우던 개를 잃어버려서 슬퍼해요.\n",
      "--------------------------------------------------\n",
      "Processing: 05851-F-97-ZH-A-LAR001-1344815.wav\n",
      "CER: 0.0000\n",
      "Transcription: 머리를 잘라야 한다.\n",
      "Reference: 머리를 잘라야 한다.\n",
      "--------------------------------------------------\n",
      "Processing: 01641-F-94-ZH-B-LAR022-0441366.wav\n",
      "CER: 0.2667\n",
      "Transcription: 생선을 먹던 고양이를 방한테 쫓겼다.\n",
      "Reference: 생선을 먹던 고양이를 방 안테 쪼껴따.\n",
      "--------------------------------------------------\n",
      "Processing: 01772-M-96-ZH-A-ATQ023-0388483.wav\n",
      "CER: 0.1818\n",
      "Transcription: 우리 집 근처에는 대학교가 하나 있어요. 그래서 아주 시끄럽습니다. 학생들이 많이 가는 술집도 있어요. 맨날 밤 열두시 까지 술을 먹고 음악을 틀어요. 진짜 시끄럽습니다. 집 근처에는 공원 하나도 있어요. 공원에는 호수가 하나 있는데 아주 아름답습니다. 그리고 학생들이 많이 놀고 술을 마시는 편이에요.\n",
      "Reference: 우리 집 근처에는 대학교가 하나 있어요. 그래서 아주 시끄럽습니다. 학생들이 많이 가는 술집도 있어요. 매날 밤 12시까지 술을 먹어 음막을 틀어요. 진짜 시끄럽습니다. 집 근처에는 공원 하나도 있어요. 공원에는 호수가 하나 있는데 아주 아름답습니다. 그리고 집 뒤에는 은내 하나 있어요. 아주 편리합니다.\n",
      "--------------------------------------------------\n",
      "Processing: 00411-M-98-ZH-A-ATQ003-0083322.wav\n",
      "CER: 0.3846\n",
      "Transcription: 저의 승일은 이십구일일이에요.\n",
      "Reference: 저의 생일은 29일 이에요.\n",
      "--------------------------------------------------\n",
      "Processing: 02116-F-97-ZH-A-LAR019-0496763.wav\n",
      "CER: 0.0000\n",
      "Transcription: 사람들은 주택 가격이 떨어지기를 바란다.\n",
      "Reference: 사람들은 주택 가격이 떨어지기를 바란다.\n",
      "--------------------------------------------------\n",
      "Processing: 07353-F-1-JA-A-LAR020-1790370.wav\n",
      "CER: 0.2941\n",
      "Transcription: 올해는 찬년보다 빨리 따뜻해지면 좋겠다.\n",
      "Reference: 고래는 천년보다 팔리 타뜻해지면 좋겠다.\n",
      "--------------------------------------------------\n",
      "Processing: 03576-F-2-JA-A-ATQ001-1837519.wav\n",
      "CER: 0.0000\n",
      "Transcription: 하루에 일곱시간 자요.\n",
      "Reference: 하루에 일곱시간 자요.\n",
      "--------------------------------------------------\n",
      "Processing: 08604-F-82-JA-A-SPT001-2114593.wav\n",
      "CER: 0.3759\n",
      "Transcription: 제 한국어 공부에 대해서 이야기할게요. 제가 한국어를 공부하는 이유는 저는 요리를 좋아해서 요리 방송을 재미있게 보기 때문이에요. 그리고 제가 한국어 공부하면서 힘들 때는 한국어를 배우는 게 제일 힘들다고 생각해요. 그리고 앞으로는 한국어 공부 계획이 제 한국어 공부 계획에 대해서 계획을 제일 많이 공부할 것 같아요.\n",
      "Reference: 제 한국어 공부에 대해서 이야기할게요. 제가 한국어를 공부하는 이유는 저는 요리를 좋아해서 요리 방송을 재미있게 보기 땜니에요. 그리고 제가 한국어 공부 하면서 힘들 때는 말하기 할 때예요. 말하기가 저한테 좀 어려웠거든요. 그리고 제 한국어 공부 계획은 계획은 더빅 시험을 보고 더빅 육급을 받기에요.\n",
      "--------------------------------------------------\n",
      "Processing: 01097-F-91-ZH-A-EIG001-0253827.wav\n",
      "CER: 0.1368\n",
      "Transcription: 오늘은 제이슨 씨의 생일입니다. 그래서 생일 파티를 열었습니다. 제이슨 씨는 친구를 18명을 초대했습니다. 친구들은 지금 교실에서 음악을 들고 춤을 추는 사람도 있고 그리고 게임을 하고 있는 친구도 있습니다. 그리고 지금은 안나는 친구들이랑 같이 게임을 하고 있습니다.\n",
      "Reference: 오늘은 제이슨 씨의 생일입니다. 그래서 생일 파티를 열었습니다. 제이슨 씨는 친구를 18명을 초대했습니다. 친구들은 지금 교실에서 음악을 들고 춤을 추는 사람도 있고 그리고 게임을 하고 있는 친구도 있습니다. 그리고 지금은 안나 씨는 제이슨 씨랑 케이크를 먹고 이야기를 나누고 있습니다.\n",
      "--------------------------------------------------\n",
      "Processing: 00778-M-94-ZH-A-LAR014-0174298.wav\n",
      "CER: 0.0000\n",
      "Transcription: 너는 클래식 음악 듣는 것을 좋아하지, 그렇지?\n",
      "Reference: 너는 클래식 음악 듣는 것을 좋아하지, 그렇지?\n",
      "--------------------------------------------------\n",
      "Processing: 05033-F-0-ZH-A-LAR012-1056927.wav\n",
      "CER: 0.0000\n",
      "Transcription: 그 식당은 음식 음식 맛이 좋다고 한다.\n",
      "Reference: 그 식당은 음식 음식 맛이 좋다고 한다.\n",
      "--------------------------------------------------\n",
      "Processing: 01580-M-96-ZH-A-LAR012-0443868.wav\n",
      "CER: 0.1875\n",
      "Transcription: 그 식당은 음식 맛이 좋다고 한다.\n",
      "Reference: 그 식당은 음식 마 음식 맛이 좋다고 한다.\n",
      "--------------------------------------------------\n",
      "Processing: 00430-M-1-ZH-A-LAR022-0094608.wav\n",
      "CER: 0.0000\n",
      "Transcription: 생선을 먹던 고양이가 강아지한테 쫓겼다.\n",
      "Reference: 생선을 먹던 고양이가 강아지한테 쫓겼다.\n",
      "\n",
      "--------------------------------------------------\n",
      "Processing: 00697-F-1-ZH-A-ATQ020-0156938.wav\n",
      "CER: 0.1000\n",
      "Transcription: 이 시험 끝나면은 저는 점심 밥을 먹으러 갈 거예요.\n",
      "Reference: 이 시험 끝나면은 저는 점심밥을 먹으러 갈꺼에요.\n",
      "--------------------------------------------------\n",
      "Processing: 01967-F-0-ZH-A-ATQ010-0458574.wav\n",
      "CER: 0.0000\n",
      "Transcription: 저 친구 우산을 선물로 주셔서요.\n",
      "Reference: 저 친구 우산을 선물로 주셔서요.\n",
      "--------------------------------------------------\n",
      "Processing: 06613-F-95-ZH-A-ATQ028-1460242.wav\n",
      "CER: 0.0392\n",
      "Transcription: 입을 구할 때 가장 중요하게 생각하는 것은 햇빛이 많은 것입니다. 왜냐하면 햇빛이 많으면 벌레가 별로 없을 거라고 생각합니다.\n",
      "Reference: 입을 구할 때 가장 중요하게 생각하는 것은 햇빛이 많은 것입니다. 왜냐면 햇빛이 많으면 꼴레가 별로 없을 거라고 생각합니다.\n",
      "--------------------------------------------------\n",
      "Processing: 11347-F-1-JA-A-PDT003-2444776.wav\n",
      "CER: 0.0488\n",
      "Transcription: 이건 제가 새로 산 노트북이라 세연 법을 아직 잘 몰라요. 그래서 선배한테 빌려주고 싶지 않아요. 선배가 노트북이 필요하면 학교에 가서 학생회에 컴퓨터를 빌리거나 도서관에 컴퓨터를 쓰기도 가능합니다.\n",
      "Reference: 이건 제가 새로 산 노트북이라 사용법을 아직 잘 몰라요. 그래서 선배한테 빌려주고 싶지 않아요. 선배가 노트북이 필요하면 학교에 가서 학생회의 컴퓨터를 빌리거나 도서관의 컴퓨터를 쓰기도 가능합니다.\n",
      "--------------------------------------------------\n",
      "Processing: 00275-M-98-ZH-A-ATQ002-0054988.wav\n",
      "CER: 0.0000\n",
      "Transcription: 오늘 아침에 일곱 시에 일어났어요.\n",
      "Reference: 오늘 아침에 일곱시에 일어났어요.\n",
      "--------------------------------------------------\n",
      "Processing: 01644-F-95-ZH-A-LAR030-0347232.wav\n",
      "CER: 0.0526\n",
      "Transcription: 아침에 아무것도 먹지 않은 사람들이 많습니다.\n",
      "Reference: 아침에 아무것도 먹지 않는 사람들이 많습니다.\n",
      "--------------------------------------------------\n",
      "Processing: 00590-F-3-ZH-A-SPT006-0130817.wav\n",
      "CER: 0.6111\n",
      "Transcription: 제가 지각했던 겨험은 제일 기억에 남는 것이 바로 제가 지난 학기에 학교에 가까워 있는 케하우스에 선발됐지 못하고 학교에 좀 이십 분이나 삼십 분 거리에 떨어지는 제야어스에 선발되었어요. 그래서 제가 지각하는 제일 중한우 보니까 바로 제가 아침에 준비하는 행동이 늘려서 걸렸어요. 그래서 제가 지각하는 시간이 제일 중요하다고 생각해서 제가 지각하는 시간이 제일 중요하다고 생각해서 제가 지각하는 시간이 제일 중요하다고 생각해서 제가 지각하는 시간이 제일 중요하다고 생각해서 제가 지각하는 시간이 제일 중요하다고 생각해서 제가 지각하는 시간이 제일 중요하다고 생각해서 제가 지각하는 시간이 제일 중요하다고 생각해서 제가 지각하는 시간이 제일 중요하다고 생각해서 제가 지각하는 시간이 제일 중요하다고 생각해서 제가 지각하는 시간이 제일 중요하다고 생각합니다.\n",
      "Reference: 제가 지각했던 경험믄 제일 기억에 남는 것이 바로 제가 지나기에 학교에 가까워 있는 케어하우스에 선발되지 못하고 어 학교에 좀 20분이나 30분 거리에 떨어져 있는 째어하우스에 선발되었어요. 그래서 제가 지각하는 제일 중요하는 원이가 바로 제가 아침에 준비하는 행동이 느려서 그래요 . 제가 화장하면 거의 1시간 고되게 하면 또 30분 거의 그렇게 걸리고요. 제가 제일 충분한 시간을 드 말씀드린 거예요. 그리고 그 저 어 막기 위해서 제가 이제는 좀 화장을 간단하고 신속하게 하는 방법을 배우며 어 그리고 편안한 시간을 더 빨리 하고 어 시간을 좀 더 넉넉하게 준비하고 있습니다.\n",
      "--------------------------------------------------\n",
      "Processing: 02516-F-1-ZH-A-LAR009-0580616.wav\n",
      "CER: 0.0000\n",
      "Transcription: 나는 행복하게 끝나는 영화가 좋다.\n",
      "Reference: 나는 행복하게 끝나는 영화가 좋다.\n",
      "--------------------------------------------------\n",
      "Processing: 08796-F-95-ZH-A-PDT002-1953924.wav\n",
      "CER: 0.5113\n",
      "Transcription: 선생님 안녕하세요. 저희는 다음 주 수업에서 발표 순서를 좀 바꾸고 싶어서 찾아 맞습니다. 다음 주 저희 팀은 오전 발표 예정입니다. 그런데 저희가 지금 준비하는 자료가 하나 빠져 있어서 그거 한 내일 정신대까지 준비를 가능할 것 같습니다. 내일 오전 그리고 그 수업에서 발표할 수 있는 자료를 좀 바꿀 수 있는 자료를 좀 바꿀 수 있는 자료입니다. 그래서 저희는 다음 주 수업에서 발표 순서를 좀 바꿔주실 수 있을 것 같습니다. 다음 주 수업에서 다음 주 수업에서 발표 순서를 좀 바꿔주실 수 있을까요.\n",
      "Reference: \n",
      "선생님 안녕하세요. 저희는 다음 주 수업에서 발표 순서를 좀 봐보고 싶어서 찾아 맞습니다. 다음 주 저희 팀은 오전 발표 예정입니다. 그런데 저희가 지금 준비하는 자료가 하나 빠져 있어서 그거 한 내일 점심 때까지 준비를 가능할 것 같습니다. 내일 오전 그리고 그 자료를 준비를 해가지고 다음 주 수업에서 잘 발표하고 싶으면은 오전에 발표하면 조금 급한 것 같고 오후에 바꾸고 싶습니다. 오후로 바꾸고 싶습니다. 선생님 괜찮다고 하시면 저희가 이미 어후 팀이랑 협의를 해서 그 팀도 괜찮다고 하셔서 선생님 괜찮다고 하시면 저희는 오후에 발표하겠습니다.\n",
      "--------------------------------------------------\n",
      "Processing: 01304-F-96-ZH-A-SPT006-0397675.wav\n",
      "CER: 0.8671\n",
      "Transcription: 지각했던 경험은 아주 아주 많아요. 한 이틀 전에 수업하러 갔는데 2 3분 정도 지각을 했어요. 저는 길게는 지각을 하지 않았고 항상 좀 2 3분 정도 늦었던 것 같아요. 네. 좀 늦었던 것 같고 근데 수업이 없어서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고 그래서 좀 늦었던 것 같고.\n",
      "Reference: 지각했던 경험은 아주 아주 많아요. 한 이틀 전에 수업 하러 갔는데 2 3분 정도 지각을 했어요. 저는 길게는 지각을 하지 않았고 항상 좀 2 3분 정도는 늦었던 것 같아요. 네 주로는 차가 막히거나 아니면은 제가 준비하는 시간이 너무 너무 길게 해서 지각을 했습니다. 최대한 지각을 하지 않도록 빨리빨리 준비하려고 하는데 네 항상 그렇게 빨리빨리 하게 준비를 할 수가 없습니다.\n",
      "--------------------------------------------------\n",
      "Processing: 01580-M-96-ZH-A-EIG003-0444074.wav\n",
      "CER: 0.6341\n",
      "Transcription: 이십대 삼십대 삼십대 젊은인들의 스마트폰 사용 조사의 걸과를 따르면 이십대의 젊은들은 에스엔스 에스엔스 에스엔스를 제일 많이 사용하는 걸과를 나왔어요. 오십칠퍼센트를 나왔고 두 번째는 문자 메신저를 한 것이 그렇고 세 번째는 건물을 많이 나왔어요. 쇼핑은 사십팔퍼센트를 나왔고 문자 메신저를 한 것이 그렇고 세 번째는 건물을 많이 사용하고 있습니다.\n",
      "Reference: 20대 20대 30대 젊은이들의 스마트폰 사용 조사에 결과를 따르면 20대 젊은이들이 sns sns sns를 제일 많이 협상하는 결과를 많이 나왔어요. 57%를 나왔고 두 번째는 문자 메실 메신저를 한 것일 거고 세 번째는 검색이었어요. 반대 반면에 30대 젊은 젊은이들은 검색 하는 것을 한 결과를 나왔고 두 번째는 쇼핑하는 거고 세 번째는 문자 메신저를 하는 것으로 나왔어요. 역시 20대 요즘 20대 젊은 사람들이 주로 sns를 많이 사용하는 결과들도 나왔으니까 그런 것 같아요.\n",
      "--------------------------------------------------\n",
      "Processing: 09476-F-3-JA-A-PDT002-2165344.wav\n",
      "CER: 0.4091\n",
      "Transcription: 선생님 다음 주 수업에서 발표를 해야 하는데 발표 준비가 아직 안 끝나서 발표 순서를 바꾸고 싶습니다. 완벽한 상태로 발표를 하기 위해 발표 순서를 바꿔줄 수 있을까?\n",
      "Reference: 선생님 다음 주 수업에서 발표를 해야 하는데 발표 준비가 아직 안 끝나서 발표 순서를 바꾸고 싶습니다. 완벽한 상태로 발표를 하기 위해 발표 순서를 바꿔주실 수 있을니까? 발표 준비를 끝낼 수 없었던 곳은 제 잘못이라 다음부터는 같은 실수를 하지 않겠습니다. 잘 부탁드립니다.\n",
      "--------------------------------------------------\n",
      "Processing: 02345-F-96-ZH-A-ATQ025-0591791.wav\n",
      "CER: 0.0824\n",
      "Transcription: 제 고향은 중국 수천성에 있습니다. 바로 훠꽃와 펜다로 유명한 곳이죠. 제 고향에 겨울엔 한국이랑 많이 달라요. 한국의 겨울 날씨는 건조하고 바람이 많이 불 것 같은데 제 고향에는 겨울에는 날씨가 습하고 추웁니다.\n",
      "Reference: 제 고향은 중국 스촨성에 있습니다. 바로 호코와 팬다로 유명한 곳이죠. 제 고향의 겨울은 한국이랑 많이 달라요. 한국의 겨울 날씨는 건조하고 바람이 많이 불 것 같은데 제 고향에는 겨울에는 날씨가 습하고 추웁니다.\n",
      "--------------------------------------------------\n",
      "Processing: 07667-F-0-JA-B-LAR013-1704666.wav\n",
      "CER: 0.0000\n",
      "Transcription: 동물 키울 수 있는 크고 좋은 집에 살고 싶어.\n",
      "Reference: 동물 키울 수 있는 크고 좋은 집에 살고 싶어.\n",
      "--------------------------------------------------\n",
      "Processing: 02095-F-98-ZH-A-LAR004-0489366.wav\n",
      "CER: 0.0000\n",
      "Transcription: 그 사람은 매일 샤워를 한다.\n",
      "Reference: 그 사람은 매일 샤워를 한다.\n",
      "--------------------------------------------------\n",
      "Processing: 00445-F-94-ZH-A-LAR001-0098970.wav\n",
      "CER: 0.0000\n",
      "Transcription: 머리를 잘라야 한다.\n",
      "Reference: 머리를 잘라야 한다.\n",
      "--------------------------------------------------\n",
      "Processing: 02225-F-3-ZH-A-ATQ003-0547252.wav\n",
      "CER: 0.1818\n",
      "Transcription: 생일은 유월 십팔일입니다.\n",
      "Reference: 생일은 육월 삽팔일입니다.\n",
      "\n",
      "--------------------------------------------------\n",
      "Processing: 06374-F-96-JA-A-ATQ020-1465145.wav\n",
      "CER: 0.0526\n",
      "Transcription: 이 시험이 끝난 다음에는 친구랑 놀러 갈 거예요.\n",
      "Reference: 이 시험이 끝난 다음에는 친구랑 놀러 갈 거에요.\n",
      "--------------------------------------------------\n",
      "Processing: 01593-M-99-ZH-A-ATQ019-0397246.wav\n",
      "CER: 0.0000\n",
      "Transcription: 돈이 많으면 세계 여행 가고 싶어요.\n",
      "Reference: 돈이 많으면 세계 여행 가고 싶어요.\n",
      "--------------------------------------------------\n",
      "Processing: 02043-F-97-ZH-A-LAR009-0478800.wav\n",
      "CER: 0.0000\n",
      "Transcription: 나는 행복하게 끝나는 영화를 좋아한다.\n",
      "Reference: 나는 행복하게 끝나는 영화를 좋아한다.\n",
      "--------------------------------------------------\n",
      "Processing: 01274-F-2-JA-A-LAR018-0483189.wav\n",
      "CER: 0.0000\n",
      "Transcription: 나는 고기 요리만 시키고 야채는 안 먹는다.\n",
      "Reference: 나는 고기 요리만 시키고 야채는 안 먹는다.\n",
      "--------------------------------------------------\n",
      "Processing: 00140-F-99-ZH-A-LAR014-0027276.wav\n",
      "CER: 0.0000\n",
      "Transcription: 너는 클래식 음악을 듣는 거 좋아하지, 그렇지?\n",
      "Reference: 너는 클래식 음악을 듣는 거 좋아하지? 그렇지? \n",
      "--------------------------------------------------\n",
      "Processing: 06738-F-96-ZH-A-ATQ023-1483560.wav\n",
      "CER: 0.1111\n",
      "Transcription: 집 근처에는 목걸이가 있습니다. 목걸이는 여러 가지 가게가 있고 편의점도 있어서 매우 편이하고요. 세탁소나 편의시설물도 많습니다.\n",
      "Reference: 집 근처에는 먹거리가 있습니다. 먹거리는 여러 가지 가게가 있고 편의점도 있어서 매우 편이하고요. 세탁소나 편의 시설물도 많습니다.\n",
      "--------------------------------------------------\n",
      "Processing: 01692-F-96-ZH-A-ATQ021-0454913.wav\n",
      "CER: 0.0741\n",
      "Transcription: 방 안에 컴퓨터 많고 채 많고 책상 두 개 있고 나머지 아무것도 없어요.\n",
      "Reference: 방 안에 컴퓨터 많고 체 많고 책상 2개 있고 나머지 아무것도 없어요.\n",
      "--------------------------------------------------\n",
      "Processing: 03159-F-0-JA-A-LAR020-0756757.wav\n",
      "CER: 0.0000\n",
      "Transcription: 올해는 작년보다 빨리 따뜻해지면 좋겠다.\n",
      "Reference: 올해는 작년보다 빨리 따뜻해지면 좋겠다.\n",
      "--------------------------------------------------\n",
      "Processing: 01539-M-2-ZH-A-LAR018-0325821.wav\n",
      "CER: 0.2857\n",
      "Transcription: 나는 거가 요리 먹는 싶어 고쳐나다.\n",
      "Reference: 나는 고개 요리 먹는 싶어 끝은 나다.\n",
      "--------------------------------------------------\n",
      "Processing: 01617-F-95-ZH-A-LAR018-0529838.wav\n",
      "CER: 0.0000\n",
      "Transcription: 나는 고기 요리만 시키고 야채는 안 먹는다.\n",
      "Reference: 나는 고기 요리만 시키고 야채는 안 먹는다.\n",
      "--------------------------------------------------\n",
      "Processing: 02439-F-88-ZH-A-LAR027-0585141.wav\n",
      "CER: 0.0000\n",
      "Transcription: 담배 피는 사람 수가 매년 증가하고 있다.\n",
      "Reference: 담배 피는 사람 수가 매년 증가하고 있다.\n",
      "--------------------------------------------------\n",
      "Processing: 09692-F-4-JA-A-ATQ018-2162149.wav\n",
      "CER: 0.0000\n",
      "Transcription: 시간이 있을 때 보통 유튜브를 보거나 친구하고 전화해요.\n",
      "Reference: 시간이 있을 때 보통 유튜브를 보거나 친구하고 전화해요.\n",
      "--------------------------------------------------\n",
      "Processing: 02129-F-96-ZH-A-LAR029-0501366.wav\n",
      "CER: 0.1579\n",
      "Transcription: 11시 반 기차가 이미 역을 떠나는지 모르겠다.\n",
      "Reference: 열한 시 반 기차가 이미 역을 떠났는지 모르겠다.\n",
      "--------------------------------------------------\n",
      "Processing: 09228-F-85-ZH-A-ATQ028-2086237.wav\n",
      "CER: 0.3000\n",
      "Transcription:  내 가장 중요하게 생각하는 게 일단은 첫 번째는 계학서입니다. 요즘 계약이 아닐까 이런 질문은 갖고 자세히 살펴야 합니다. 그리고 집 안에 가구인지 수도 잘 되어 가고 있는지를 잘 확인하시고 그리고 온도 겨울에 있는 길을 잘 살펴볼 수 있습니다.\n",
      "Reference: 저한테 가장 중요하게 생각하는 게 일단은 첫 번째는 계약서입니다. \"이중 계약이 아닐까?\" 이런 질문을 갖고 자세 자세히 살펴야 합니다. 그리고 집 안에 가구 있는지 수도 잘 돼 가고 있는지를 잘 확인하시고 그리고 온도 겨울에 추우니까 혹시 온도 방 방음이 잘 되는지 확인 하시고.\n",
      "--------------------------------------------------\n",
      "Processing: 09331-F-2-JA-A-ATQ028-2293863.wav\n",
      "CER: 0.0714\n",
      "Transcription: 제 생각에는 집을 구할 때 집 근처에 있는 슈퍼마켓이 가장 중요해요. 왜냐하면 저는 맛있는 음식으르 먹는 걸 너무 좋아해요. 그래서 보통 매일은 요리해요. 그래서 시간이 있을 때 슈퍼마켓 가서 요리 재료를 사요.\n",
      "Reference: 제 생각에는 지브를 구할 때 집 근처에 있는 슈퍼마켓이 가장 중요해요. 왜냐하면 저는 맛있는 음식으를 먹는 걸 너무 좋아해요. 그래서 보통 매이르 요리해요. 그래서 시간이 있을 때 슈퍼마켓 가서 요리 재료를 사요.\n",
      "--------------------------------------------------\n",
      "Processing: 10108-F-98-JA-A-LAR004-2252175.wav\n",
      "CER: 0.0000\n",
      "Transcription: 그 사람은 매일 샤워를 한다.\n",
      "Reference: 그 사람은 매일 샤워를 한다.\n",
      "--------------------------------------------------\n",
      "Processing: 01394-F-94-ZH-A-LAR015-0534213.wav\n",
      "CER: 0.0909\n",
      "Transcription: 나는 집 내부 공사를 끝났다.\n",
      "Reference: 나는 집 내부 검사를 끝났다.\n",
      "--------------------------------------------------\n",
      "Processing: 00435-F-2-ZH-A-ATQ002-0095766.wav\n",
      "CER: 0.0000\n",
      "Transcription: 점심 12시.\n",
      "Reference: 점심 12시.\n",
      "--------------------------------------------------\n",
      "Processing: 00130-F-96-ZH-A-LAR021-0027014.wav\n",
      "CER: 0.0000\n",
      "Transcription: 내 친구는 항상 옆집 아이 셋을 돌봐준다.\n",
      "Reference: 내 친구는 항상 옆집 아이 셋을 돌봐준다.\n",
      "--------------------------------------------------\n",
      "\n",
      "Average CER: 0.1405\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import torch\n",
    "import random\n",
    "import nlptutti as metrics\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# 모델과 프로세서 로드\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"jwh1449/whisper_base_test\")\n",
    "processor = WhisperProcessor.from_pretrained(\"jwh1449/whisper_base_test\")\n",
    "model.generation_config.forced_decoder_ids = None\n",
    "\n",
    "# 변환할 음성 파일 경로 설정\n",
    "audio_folder = \"/content/drive/MyDrive/STTDATA/데이터모음/원본데이터\"\n",
    "json_folder = \"/content/drive/MyDrive/STTDATA/데이터모음/정답데이터\"\n",
    "\n",
    "# 모든 WAV 파일 목록 가져오기\n",
    "all_files = [f for f in os.listdir(audio_folder) if f.endswith(\".wav\")]\n",
    "selected_files = random.sample(all_files, min(100, len(all_files)))\n",
    "\n",
    "cer_list = []\n",
    "\n",
    "for file_name in selected_files:\n",
    "    file_path = os.path.join(audio_folder, file_name)\n",
    "    json_path = os.path.join(json_folder, file_name.replace(\".wav\", \".json\"))\n",
    "\n",
    "    print(f\"Processing: {file_name}\")\n",
    "\n",
    "    # 전체 파일 한 번에 로드 (분할 없음)\n",
    "    audio, sr = librosa.load(file_path, sr=16000)\n",
    "    input_features = processor(audio, sampling_rate=sr, return_tensors=\"pt\").input_features\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            input_features,\n",
    "            language=\"ko\",\n",
    "            task=\"transcribe\"\n",
    "        )\n",
    "\n",
    "    asr_text = processor.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            reference_text = data['RecordingMetadata']['orthographic']\n",
    "\n",
    "            cer_result = metrics.get_cer(reference_text, asr_text)\n",
    "            cer = cer_result['cer']\n",
    "            cer_list.append(cer)\n",
    "            print(f\"CER: {cer:.4f}\")\n",
    "    else:\n",
    "        print(\"No reference text found.\")\n",
    "\n",
    "    print(f\"Transcription: {asr_text}\")\n",
    "    print(f\"Reference: {reference_text}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "if cer_list:\n",
    "    print(f\"\\nAverage CER: {sum(cer_list)/len(cer_list):.4f}\")"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4
}
