{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!pip install datasets>=2.6.1\n",
    "!pip install git+https://github.com/huggingface/transformers\n",
    "!pip install evaluate>=0.30\n",
    "!pip install jiwer\n",
    "!pip install accelerate -U\n",
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "json_data['RecordingMetadata']['prompt']\n",
    "json_data['SpeakerMetadata']['topik_level']"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 1. 오디오 파일 경로 취합\n",
    "import glob\n",
    "\n",
    "path = \"/content/drive/MyDrive/STTDATA/데이터모음/원본데이터/*\"\n",
    "raw_data_list = glob.glob(path)\n",
    "raw_data_list = sorted(raw_data_list)\n",
    "print(f\"file_list : {raw_data_list[:10]}\")\n",
    "print(len(raw_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 2. json 파일 경로 취합\n",
    "import glob\n",
    "\n",
    "path = \"/content/drive/MyDrive/STTDATA/데이터모음/정답데이터/*\"\n",
    "labeled_data_list = glob.glob(path)\n",
    "labeled_data_list = sorted(labeled_data_list)\n",
    "print(f\"file_list : {labeled_data_list[:10]}\")\n",
    "print(len(labeled_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "transcript_list = []\n",
    "for labeled_data in tqdm(labeled_data_list):\n",
    "    with open(labeled_data, \"r\", encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "        json_data = json_data['RecordingMetadata']['orthographic']\n",
    "        transcript_list.append(json_data)\n",
    "\n",
    "df = pd.DataFrame(data=transcript_list, columns = [\"transcript\"])\n",
    "\n",
    "# 텍스트 데이터로 만든 데이터프레임에 음성 파일 경로 컬럼을 추가\n",
    "df[\"raw_data\"] = raw_data_list\n",
    "\n",
    "# Null data 유무 확인\n",
    "df.isnull().values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from datasets import Audio\n",
    "\n",
    "# 오디오 파일 경로를 dict의 \"audio\" 키의 value로 넣고 이를 데이터셋으로 변환\n",
    "# 이때, Whisper가 요구하는 사양대로 Sampling rate는 16,000으로 설정한다.\n",
    "ds = Dataset.from_dict({\"audio\": [path for path in df[\"raw_data\"]],\n",
    "                       \"transcripts\": [transcript for transcript in df[\"transcript\"]]}).cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "\n",
    "# 데이터셋을 훈련 데이터와 테스트 데이터, 밸리데이션 데이터로 분할\n",
    "train_testvalid = ds.train_test_split(test_size=0.2)\n",
    "test_valid = train_testvalid[\"test\"].train_test_split(test_size=0.5)\n",
    "datasets = DatasetDict({\n",
    "    \"train\": train_testvalid[\"train\"],\n",
    "    \"test\": test_valid[\"test\"],\n",
    "    \"valid\": test_valid[\"train\"]})\n",
    "\n",
    "# 작성한 데이터셋을 허깅페이스에 업로드\n",
    "datasets.push_to_hub(\"jwh1449/AIhub_foreign_dataset\")\n",
    "print(\"완료\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 1. 오디오 파일 경로 취합\n",
    "import glob\n",
    "\n",
    "path = \"/content/drive/MyDrive/STTDATA/데이터모음/원본데이터/*\"\n",
    "raw_data_list = glob.glob(path)\n",
    "raw_data_list = sorted(raw_data_list)\n",
    "print(f\"file_list : {raw_data_list[:10]}\")\n",
    "print(len(raw_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 2. json 파일 경로 취합\n",
    "import glob\n",
    "\n",
    "path = \"/content/drive/MyDrive/STTDATA/데이터모음/정답데이터/*\"\n",
    "labeled_data_list = glob.glob(path)\n",
    "labeled_data_list = sorted(labeled_data_list)\n",
    "print(f\"file_list : {labeled_data_list[:10]}\")\n",
    "print(len(labeled_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import WhisperFeatureExtractor, WhisperTokenizer\n",
    "\n",
    "# 파인튜닝을 진행하고자 하는 모델의 feature extractor를 로드\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-base\")\n",
    "\n",
    "# 파인튜닝을 진행하고자 하는 모델의 tokenizer를 로드\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-base\", language=\"Korean\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 전체 데이터셋에서 각 split의 50%만 불러오기\n",
    "low_call_voices = load_dataset(\n",
    "    \"jwh1449/AIhub_foreign_dataset\",\n",
    "    split={\n",
    "        \"train\": \"train[:50%]\",\n",
    "        \"test\": \"test[:50%]\",\n",
    "        \"valid\": \"valid[:50%]\"\n",
    "    }\n",
    ")\n",
    "\n",
    "low_call_voices.push_to_hub(\"jwh1449/AIhub_foreign_dataset2\")\n",
    "print(\"완료\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 전체 데이터셋에서 각 split의 50%만 불러오기\n",
    "low_call_voices = load_dataset(\n",
    "    \"jwh1449/AIhub_foreign_dataset\",\n",
    "    split={\n",
    "        \"train\": \"train[-50%:]\",\n",
    "        \"test\": \"test[-50%:]\",\n",
    "        \"valid\": \"valid[-50%:]\"\n",
    "    }\n",
    ")\n",
    "\n",
    "low_call_voices.push_to_hub(\"jwh1449/AIhub_foreign_dataset3\")\n",
    "print(\"완료\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 데이터셋을 업로드할 때 접근을 제한하거나 비공개로 설정한 경우 허깅페이스 로그인이 필요하다.\n",
    "low_call_voices = load_dataset(\"jwh1449/AIhub_foreign_dataset3\")\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    # 오디오 파일을 16kHz로 로드\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # input audio array로부터 log-Mel spectrogram 변환\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # target text를 label ids로 변환\n",
    "    batch[\"labels\"] = tokenizer(batch[\"transcripts\"]).input_ids\n",
    "    return batch"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4
}
